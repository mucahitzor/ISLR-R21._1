{"title":"What Is Statistical Learning?","markdown":{"yaml":{"output":"html_document","editor_options":{"chunk_output_type":"console"}},"headingText":"What Is Statistical Learning?","containsRefs":false,"markdown":"\n\n```{r}\n#| echo: false\n#| warning: false\n#| error: false\nlibrary(ISLR)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(sjPlot)\n```\n\n\nQuestion: How to improve sales of our product?\n\nWe have a data set:\n\n```{r}\nadvertising = read_csv(\"./data/Advertising.csv\") %>% as_tibble %>% select(-1)\nadvertising\n```\n\n$n=200$, independent variables (predictors) are `TV`, `radio`, and `newspaper` advertising spendings in thousands of dollars. We want to explore their relationship with `sales`; quantity of product sold for each advertising mixture. If we determine association between advertising and sales, we can provide adjustment of advertisement budgeds based on most effective media to increase sales; we want to develop an accurate model that ca be used to predict sales on the basis of three media budgets.\n\nWe denote all input variables (actual--realized) as $X_1, X_2, ..., X_p$ and use $X$ to refer all of them. In this case $X = (X_1, X_2, X_3)$. Sales is denoted with $Y$.\n\nThis means we assume a relationship between $Y$ and $X$ in a form of\n\n$$\nY = f(X) + \\epsilon\n$$ (2.1)\n\n-   Here $f$ is some fixed, but unknown function of $X$.\n-   $\\epsilon$ is a random *error term* =\\> independent of $X$ and has a mean zero.\n\nSo $f$ represents systematic information that $X$ provides about $Y$.\n\n$f$ is generally unknown. We will need to estimate $f$ baed on the observed points =\\> $\\hat{f}$.\n\nStatistical learning refers to a set of approaches for estimating $f$.\n\n## Why estimate $f$?\n\nTwo reasons: \\* *prediction* \\* *inference*\n\n**Prediction**\n\nMost of the time we have $X$ but we might not have $Y$. In this setting, since the error term averages to zero, we can predict $Y$ using\n\n$$\n\\hat{Y} = \\hat{f}X\n$$ (2.2)\n\nHere $\\hat{f}$ is treated as a *black box*. We are not concerned with the exact form of $\\hat{f}$, we just want to have accurate predictions of $Y$.\n\nImagine we have $X = (X_1, X_2, \\dots, X_p)$; blood sample characteristics of patients. $Y$ is a variable showing the patient's risk for a adverse reaction to a drug. We don't want to give the drug and see the reaction, so we want to predict reactions.\n\nThe accuracy of our predictions $\\hat{Y}$ of $Y$, depends on two quantities:\n\n-   *reducible error*\n\n    Generally $\\hat{f}$ will not be a perfect estimate for $f$. This inaccuracy will introduce some error, which we call reducible error since we can improve our accuracy of $\\hat{f}$ using the most appropriate statistical leraning method.\n\n-   *irreducible error*\n\n    Even if we estimate $f$ perfectly, our estimated response would take the form $\\hat{Y} = f(X)$; our predictions would still get some error. This is because $Y$ is not just a function of $X$ but also a function of $\\epsilon$, which cannot be predicted by $X$. So the level of $\\epsilon$ would also effect our prediciton accuracy. And we cannot remove this error; thus, irreducible.\n\n    $\\epsilon$ is larger than zero; because $\\epsilon$ may contain some variables we don't include in our model, but effect $Y$.\n\n**Inference**\n\nHere we want to understand the way that $Y$ is affected by $X$. In this setting, we wish to estimate $f$ but we are not concerned with predicting. We want to understand the relationship between $X$ and $Y$; how $Y$ changes as $X$ changes. We **don't** treate $\\hat{f}$ as a *black box* now since we need to know its exact form. In this setting we are interested in answering questions such as\n\n-   *Which predictors are associated with the response?*\n\n    Usually not all predictors are associated with $Y$. We need to identify the *important* predictors among a large set of possible predictors.\n\n-   *What is the relationship between the response and each predictor?*\n\n    Some predictors have positive some negative association with $Y$. Depending on the complexity of $f$, the relationship between $Y$ and $X_i$ may also depend on the values of other predictors($X_j$) =\\> *synergy*\n\n-   *Can the relationship between* $Y$ *and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?*\n\nSometimes we are interested with prediction: Identifying individuals who will respond positively to a mailing, based on observations of demographic variables. Here we are not interested with understanding the relationship of demographic variables and response, we just want an accurate model to predict the response using the predictors. This is prediction.\n\nBut often we are interested to answer questions like: *Which media contribute to sales?*, *Which media generate the biggest boost in sales?*, or *How much increase in sales is associated with a given increase in* `TV` *advertising?*. This is inference.\n\nAnd sometimes we want a combination of both: *Values of homes based on crime rate, zoning, distance from a river, air quality, schools, size of houses etc.* and *How does air quality effect valeus of homes?*.\n\nWe use different models for prediction, inference, or combination of the two.\n\n### How Do We Estimate $f$?\n\nThere are many linear and non-linaer approaches we will discuss. But generally these models share certain characteristics. Here are they:\n\n-   We will always assume that we have observed a set of *n* different data points. These data points, observations, are called *training data*; which we will use these observations to train, or teach, our model on how to estimate $f$. Our training data will consist of $\\{(x_1,y_1), (x_2,y_2), \\dots, (x_n,y_n)\\}$, where $x_i = (x_{i1}, x_{i2}, \\dots, x_{ip})^T$\n\nWe want to apply a statistical learning method to the training data to estimate the unknown function $f$. We want to find a function $\\hat{f}$ such that $Y \\approx \\hat{f}(X)$ for any obsrvation $(X,Y)$.\n\nThese statistical learning methods can be charactarized as either *parametric* or *non-parametric*.\n\n**Parametric Methods**\n\nParametric methods involve a two step model-based approach:\n\n1.  *Select a model =\\> Make an assumption about the functional form of* $f$: is it linear, non linear?\n\nFor example a linear $f$ assumption would yield a *linear model*\n\n$$\n  f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p\n  $$ (2.4)\n\n2.  *Fit* or *train* the model\n\nAfter we select a model, we need a procedure that uses training data to *fit* or *train* the model.\n\nFor linear model, we need to estimate the parameters of the model ($\\beta_0, \\beta_1, \\dots, \\beta_p$). That is we want to find values of these parameters such that $$\n  Y \\approx \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p\n  $$ The most common approach to fitting the model (2.4) is called *ordinary least squares*. Chapter3. But there are other approaches as well.\n\nThis model-based approach is called *parametric:* we estimate $f$ via estimating a set of parameters.\n\nDisadvantage (potential): model we choose will usually not match the true unknown form of $f$ =\\> our estimates will be poor. =\\> solution: choose a *flexible* model that can fit different possible functional forms for $f$ =\\> you will need to estimate more parametrs =\\> *overfitting the data*.\n\n**Non-parametric Methods**\n\n=\\> No explicit assumptions about the functional form of $f$. The goal is to get an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly =\\> advantage over parametric approach: no assumption about the functional form of $f$--potentially accurately fit a wider range of possible shapes for $f$.\n\nDisadvantage =\\> lots of parameters to estimate =\\> very large of observations required to obtain an accurate estimate for $f$.\n\n### The Trade-Off Between Prediction Accuracy and Model Interpretability\n\nSome models are flexible some restrictive; in the sense that they can produce just a small range of functional forms to estimate $f$. Linear regression for instance is a relatively inflexible approach. Other metgods such as thin plate splines (non-parametric) are more flexible because they can generate a much wider range of possible functional forms to estimate $f$.\n\n*Why would be ever choose to use a more restrictive method instead of a very flexible approach?* :\n\n-   If we are mainly interested in inference, restrictive models are more interpretable. They give more information about each predictors effect on predicted.\n\n-   If we are mainly interested in prediction, flexible models give better fit. =\\> but may yield less accurate fits due to *overfitting!*\n\n### Supervised vs Unsupervised Learning\n\nMost statistical learning problems fall into these two categories: *supervised* or *unsupervised*.\n\nIn supervised learning for each observation of the predictor values $x_i, i = 1,\\dots, n$ there is an associated response value $y_i$. We wish to fit a model that relates the response to the predictors with the aims of either accurately predicting the response for future observations (prediction) or better understanding the relationship between the response and the predictors (inference). Linear regression, GAM, boosting, support vector machines operate in the supervised learning domain.\n\nUnsupervised leraning describes a situtaion in which for every observation $i=1,\\dots,n$ we obser a vector of values $x_i$ but no associated response $y_i$. We cannot use a linear regression model since we dont have $y_i$ values. Here we can seek to understand the relationships between the variables or between the observations; like *cluster analysis*, or clustering: to assert on the basis of $x_i,\\dots,x_n$ whether the observations fall into relatively distinct groups.\n\n## Regression vs Classisfication Problems\n\nVariables can be characterized as either *quantitative* or *qualitative*(also known as *categorical*). Quantitative varaibles take on numberical values: a person's age, height, or income, the value of a house, price of stock. Qualitative varaibles take on values n one of $K$ different *classes*, or categories: aperson's gender(male or female), the brand of a good (A,B, or C), a person's race etc.\n\nWe refer to problems with a quantitative response as *regression* problems, and probmes with a qualitative response as *classification* problems. However, the distinction is not clear-cut.\n\nLeast squares regression is used with a quantitative response, whereas logistic regression is typically used with a qualitative response. Some statistical methods, such as *K*-nearest negihbors and boosting, can be used in the case of either quantitative or qualitative.\n\nWe usually select statistical learning methods based on whether the response is quantitative or qualitative: we might use linear regression wjen quantitative and logistic regression when qualitative. But whether the *predictors* are qualitative or quantitative is usually not that important. Most of the statistical learning methods can be applied regardless of the predictor varible type.\n\n## Assessing Model Accuracy\n\nThere is no one method that dominates all others over all possible data sets. On a particular data set, one metghod may work best, but some other method may work better on a similar but differet data set. So it is important to assess the model accuracies of the methods.\n\nHere some ways to asses the model accuracy\n\n### Measuring the Quality of Fit\n\nSo, to evaluate the performance of a statistical learning method on a given data set, we need to measure how well its predictions actually match the observed data.\n\nIn the regression setting, the most commonly-used measure is the *mean squared error (MSE)*, given by\n\n$$\n\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{f}(x_i))^2\n$$\n\nMSE will be small if the predicted responses are veryt close to the true responses, and large if predicted and true responses differ substantially **on average**.\n\nHere since MSE is computed using the training data it is best to refer it as **training MSE**. But in general, we do not really care how well the method works on the training data =\\> *we are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen test data*.\n\nImagine: stock price prediction =\\> we have training and test data =\\> we already know the stock prices of the past, we dont care about the training data accuracy of the model, we want our model to predict the future prices of stocks best.\n\nOr we have blood characteristics of diabetes patients. We don't want our model to explain our existing patient's classification of diabetes or not, we want our model to predict our future patien's situation the best.\n\nMathematically:\n\nWe fit our statistical learning method on our training observations $\\{(x_1,y_1), (x_2,y_2), \\dots, (x_n,y_n)\\}$, and we obtain the estimate $\\hat{f}$. We can then compute $\\hat{f}(x_1),\\dots, \\hat{f}(x_n)$. If these are approximately equal to $y_1, \\dots, y_n$ then our training MSE will be small. Howeer, we are not interested in whether $y_i \\approx \\hat{f}(x_i)$, we want to know whether $\\hat{f}(x_0)$ is approximately equal to $y_0$, where $(x_0,y_0)$ is a *previously unseen test obsrevation not used to train the statistical learning method*.\n\nThat is, we want to choose the method that gives the lowest *test MSE*!.\n\nSo with our *test data* we can compute *test MSE*\n\n$$\n\\text{MSE}_{test} =\\frac{1}{n_{test}} \\sum(y_{test_{i}} - \\hat{f}(X_{test_i}))\n$$ (2.6)\n\nWe want the test MSE to be small as possible. We can compute test MSE via (2.6) if we have test data for different models and select the model with minimum test MSE.\n\nIf we don't have a test data, you might think our goal would be to minimize the training MSE since test and training data are colesly related. But no; minimal training MSE doesn't guarantee minimal training MSE\n\nUsually as the level of flexibility increases, the curves fit the observed data more closely =\\> lower training MSE. The level of flexibility is quantified by *degrees of freedom*. More restricted models have lower degrees of freedom. and usually the training MSE declines as flexibility increases.\n\n![](fig2.9.png)\n\nAs the flexibility of the statistical learning method increases, we observe a monotone decrease in the training MSE and a $U$-*shape* in the test MSE. This is a fundamental property of statistical learning that holds regardless of the particular data set at hand and regardless of the statistical method being used. AS model flexibility increases, training MSE will decrease, but the test MSE may not. When a given method yields a small training MSE but a large test MSE, we are said to be *overfitting* the data. This happens because our statistical learninig procedure is working too hard to find patterns in the training data, and may be picking up some patterns that are just caused by random change rather than by true properties of the unknown function $f$. When we overfit the trainin data, the test MSE will be very large because the supposed patterns that the method found in the training data simply don't exist in the test data.\n\nNote that regardless of whether or not overfitting has occured, we almost always expect the training MSE to be smaller than the test MSE because most statistical learning methods either directly or inderectly seek to mimizie the training MSE. Overfitting refers specifically to the case in which a less flexible model would have yielded a smaller test MSE.\n\nIn practice, training MSE is computed easily, but estimating test MSE is hard because usually no test data are available. We will learn approaches that can be used in practice to estimate the mininmum test MSE. One important method is *cross-validation*( Chapter 5), which is a method for estimating test MSE using the training data.\n\n### The Bias-Variance Trade-Off\n\nThe U-shape in the test MSE result of two competing properties of statistical learnig methods. The expected test MSE, for a given value $x_0$ can always be decomposed into sum of *variance* of $\\hat{f}(x_0)$, the squared *bias* of $\\hat{f}(x_0)$ and the variance of the error terms $\\epsilon$. That is\n\nThis means that to minimize the expected test error, we need to simultaneously have *low variance* and *low bias*. Since variance is always bigger than zero; $\\text{Var}(\\epsilon)$, and $\\text{Bias}(\\hat{f}(x_0))$ are nonnegative. So, the expected test MSE can never lie below $\\text{Var}(\\epsilon)$, the irreducible error from (2.3).\n\nWhat do we mean by the *variance* and *bias* of statistical learning method?\n\n*Varince* refers to the amount by which $\\hat{f}$ would change if we estimated it using a different training data set; different training data sets will result in a different $\\hat{f}$. But ideally, $\\hat{f}$ should not vary too much between training sets. If a method has high variance small changes in the training data can result in large changes in $\\hat{f}$.\n\nFlexible methods have hiher variance, because they fit better to the data points and changing any of the data points may cause the estiamte $\\hat{f}$ to chance considerably. But for example, least squares method is relatively inflexible and has low variance, because mooving any single observation will cause only a small shift in the position of the line.(2.9)\n\n*bias* refers to the error that is due to functional form of $\\hat{f}$. In real life, linear relationships are very rare. So performing linear regression will result in some bias in the estimate of $f$. If your $f$ is non-linear performing linear regression on different data sets will not produce an accurate estimate; so linear regression will result in high bias.\n\nFor example in 2.9 true $f$ is non linear; so linear regression have high bias, low variance. ![](fig2.10.png)\n\nIn 2.10 true $f$ is very close to linear, so linaer regression have low bias, low variance.\n\nGenerally more flexible methods result in less bias.\n\nAs a general rule, as we use more flexible methods the variance will increase and bias will decrease. The relative rate of change of these two quantities determines whether test MSE increases or decreases. As we increase the flexibility, the bias tends to initially decrease faster than the variance increases =\\> test MSE declines. However, at some point increasing flexibility has little impact on thebias but starts to significantly increase the variance =\\> test MSE increases.\n\n![](fig2.12.png)\n\nFigure 2.12 shows bias and variance effect to the test MSE for different $f$s. Horizontal dashed line represents $\\text{Var}(\\epsilon)$, the irreducible error; the red curve test MSE is the sum of squared bias, variance, and variance of irreducible error. In all cases bias decreases as flexibility increaes. However, the optimal flexibility is different for each $f$. In the left panel the bias initially decreaes rapidly, decreasing test MSE. In center panel true $f$ is closer to linear so there is only a small decrease in bias as flexibility increaes, and the test MSE only declines slightly before increasing rapidly as the variance increaes. Right hand panel, as flexibility increaess bias dramatically decreases because true $f$ is very non-linear. There is alsso very little increase in variance as flexibility increases =\\> tets MSE decreases before increasing.\n\nThis is called bias-variance trade off. Good test set performance of a method requires low variance as well as low squared bias. This is a trade off because it is easy to obtain a method with extremely low bias but high variance(for instance, drawing a curve that passes through every single training observation, or a method with low variance but high bias(by fitting a horizontal line to the data). Challange is finding a method wihch both the variance and squareed bias are low.\n\nIn real life, it is not possible to explicitly compute the test MSE, bias, or variance for methods. But we should keep this in mind.\n\n### The Classification Setting\n\nSo far we focused on regression setting. Problems such as bias-variance trade of also occurs in classification but in a modificated way because $y_i$ is no longer numerical.\n\nSuppose that we seek to estiamte $f$ on the basis of training observations $\\{(x_1,y_1), \\dots, (x_n,y_n)\\}$ where now $y_1,\\dots, y_n$ are qualitative.\n\nWe need to quantify the accuracy of our estimate $\\hat{f}$. We can use the training *error rate*, the proportion of mistakes that are made if we apply our estimate $\\hat{f}$ to the training observations:\n\n$$\n\\text{error rate}=\\frac{1}{n}\\sum^n_{i=1}I(y_i \\neq \\hat{y_i})\n$$ (2.8)\n\n$\\hat{y_i}$ is the predicted class label for the $i$th observation using $\\hat{f}$. $I(y_i \\neq \\hat{y_i})$ is an *indicator variable* that equals 1 if $y_i \\neq \\hat{y_i}$ and zero if ${y_i = \\hat{y_i}}$. If $I(y_i \\neq \\hat{y_i}) = 0$ then $i$th observation was classified correctly, otherwise it was misclassified. So (2.8) computes the fraction of incorrect classifications.\n\n(2.8) is *training error*. But as the regression setting we are more interested in *test error* rate. The *test error* rate associated with a set of test observations of the form\n\n$$\n\\text{error rate}_{test} = \\frac{1}{n_{test}}\\sum_{i=1}^{n_{test}}(I(y_{test_i} \\neq \\hat{y}_{test_i}))\n$$ (2.9)\n\nA *good* classifier is one for which the test error is smallest.\n\n**The Bayes Classifier**\n\nWe can minimize test error rate by a very simple classifier that *assigns each observation to the most likely class, given its predictor values*. In other words, we should simply assign a test observation with predictor vector $x_0$ to the class $j$ for which\n\n$$\nPr(Y = j | X = x_0)\n$$ (2.10)\n\nis largest. This is *conditional probability:* it is the probabilty that $Y=j$ given the observed predictor vector $x_0$. This classifier is called *Bayes classifier*.\n\nIn a two-class problem where there are only two possible response values, *class 1* or *class2*, the Bayes classifier corresponds to predicting class one if $Pr(Y=1 | X = x_0) > 0.5$, and class two otherwise.\n\nImagine having $X = (X_1, X_2)$. For each value of $X_1$ and $X_2$ there will be a different probability of the response being class 1 or 2. For $Pr(Y=class1 | X = (X_2,X_2)) > 0.5$ and $Pr(Y=class2 | X = (X_1,X_2))$.\n\nThe Bayes classifier produces the lowest possible test error rate, called the *Bayes error rate*. Since the Bayes classifer will always choose the class for which $Pr(Y = j | X = x_0)$ is largest, the error rate at $X=x_0$ will be $1-\\max_jPr(Y =j | X = x_0)$. In general, the overall Bayes error rate is given by\n\n$$\n\\text{Bayes error rate} = 1 - E(\\max_jPr(Y =j | X))\n$$ (2.11)\n\nwhere the expectation averages the probabilty over all possible values of X. The Bayes eror rate is analogous to the irreducible eror.\n\n**K-Nearest Neighbors**\n\nIn theory we always want to predict qualitative responses using the Bayes classifier. But for real data, we do not know the conditional distribution of $Y$ given $X$, and so computing the Bayes classfier is impossible. So Bayes classifier is like a gold standard to compare other methods.\n\nMany approaches attemp to estiamte the conditional distribution of $Y$ given $X$, and then classify a given observation to the class with highest *estimated* probability. One of them is *K-nearest neighbors*(KNN) classfier.\n\nGiven a positive integer *K* and a test observation $x_0$, the KNN clasffier first identifies the *K* points in the training data that are closest to $x_0$, represented by $N_0$. It then esitmates the conditional probability for class *j* as the fraction points in $N_0$ whose response values equal to $j$.\n\n$$\nPr(Y = j | X = x_0) = \\frac{1}{K}\\sum_{i \\in N_0}I(y_i=j)\n$$ (2.12)\n\nFinally, KNN applies Bayes rule and classifies the test observation $x_0$ to the class with the largest probability.\n\n![](fig2.14.png)\n\nFigure 2.14 provides an illustrative example of the KNN approach. Left panel =\\> Our goal is to make prediction for the black cross point. When $K=3$ KNN will identify the 3 oservations that are closest to the cross. There are two blue and one orange points; $Pr(Y=orange | X = x_{cross}) = 1/3$, and $Pr(Y=blue | X = x_{cross}) = 2/3$ =\\> KNN will predict that the black cross belongs to the blue class.\n\nThe choice of K is very important. as K increases flexibility decreases =\\> high bias, but low variance.\n\nJust like in regression setting there is not a strong relationship between the training error rate and the test error rate.\n\n![](fig2.17.png)\n\nas in the regression setting, the training error rate consistently declines as the flexibility($1/K$) increases. However, the test error rate again have a characteristic U-shape.\n\nIn both regression and classification settings, choosing the correct level of flexibility is critical. The bias-variance tradeoff =\\> U-shape in the test error, can make this a difficult task.\n","srcMarkdownNoYaml":"\n\n```{r}\n#| echo: false\n#| warning: false\n#| error: false\nlibrary(ISLR)\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(sjPlot)\n```\n\n# What Is Statistical Learning?\n\nQuestion: How to improve sales of our product?\n\nWe have a data set:\n\n```{r}\nadvertising = read_csv(\"./data/Advertising.csv\") %>% as_tibble %>% select(-1)\nadvertising\n```\n\n$n=200$, independent variables (predictors) are `TV`, `radio`, and `newspaper` advertising spendings in thousands of dollars. We want to explore their relationship with `sales`; quantity of product sold for each advertising mixture. If we determine association between advertising and sales, we can provide adjustment of advertisement budgeds based on most effective media to increase sales; we want to develop an accurate model that ca be used to predict sales on the basis of three media budgets.\n\nWe denote all input variables (actual--realized) as $X_1, X_2, ..., X_p$ and use $X$ to refer all of them. In this case $X = (X_1, X_2, X_3)$. Sales is denoted with $Y$.\n\nThis means we assume a relationship between $Y$ and $X$ in a form of\n\n$$\nY = f(X) + \\epsilon\n$$ (2.1)\n\n-   Here $f$ is some fixed, but unknown function of $X$.\n-   $\\epsilon$ is a random *error term* =\\> independent of $X$ and has a mean zero.\n\nSo $f$ represents systematic information that $X$ provides about $Y$.\n\n$f$ is generally unknown. We will need to estimate $f$ baed on the observed points =\\> $\\hat{f}$.\n\nStatistical learning refers to a set of approaches for estimating $f$.\n\n## Why estimate $f$?\n\nTwo reasons: \\* *prediction* \\* *inference*\n\n**Prediction**\n\nMost of the time we have $X$ but we might not have $Y$. In this setting, since the error term averages to zero, we can predict $Y$ using\n\n$$\n\\hat{Y} = \\hat{f}X\n$$ (2.2)\n\nHere $\\hat{f}$ is treated as a *black box*. We are not concerned with the exact form of $\\hat{f}$, we just want to have accurate predictions of $Y$.\n\nImagine we have $X = (X_1, X_2, \\dots, X_p)$; blood sample characteristics of patients. $Y$ is a variable showing the patient's risk for a adverse reaction to a drug. We don't want to give the drug and see the reaction, so we want to predict reactions.\n\nThe accuracy of our predictions $\\hat{Y}$ of $Y$, depends on two quantities:\n\n-   *reducible error*\n\n    Generally $\\hat{f}$ will not be a perfect estimate for $f$. This inaccuracy will introduce some error, which we call reducible error since we can improve our accuracy of $\\hat{f}$ using the most appropriate statistical leraning method.\n\n-   *irreducible error*\n\n    Even if we estimate $f$ perfectly, our estimated response would take the form $\\hat{Y} = f(X)$; our predictions would still get some error. This is because $Y$ is not just a function of $X$ but also a function of $\\epsilon$, which cannot be predicted by $X$. So the level of $\\epsilon$ would also effect our prediciton accuracy. And we cannot remove this error; thus, irreducible.\n\n    $\\epsilon$ is larger than zero; because $\\epsilon$ may contain some variables we don't include in our model, but effect $Y$.\n\n**Inference**\n\nHere we want to understand the way that $Y$ is affected by $X$. In this setting, we wish to estimate $f$ but we are not concerned with predicting. We want to understand the relationship between $X$ and $Y$; how $Y$ changes as $X$ changes. We **don't** treate $\\hat{f}$ as a *black box* now since we need to know its exact form. In this setting we are interested in answering questions such as\n\n-   *Which predictors are associated with the response?*\n\n    Usually not all predictors are associated with $Y$. We need to identify the *important* predictors among a large set of possible predictors.\n\n-   *What is the relationship between the response and each predictor?*\n\n    Some predictors have positive some negative association with $Y$. Depending on the complexity of $f$, the relationship between $Y$ and $X_i$ may also depend on the values of other predictors($X_j$) =\\> *synergy*\n\n-   *Can the relationship between* $Y$ *and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?*\n\nSometimes we are interested with prediction: Identifying individuals who will respond positively to a mailing, based on observations of demographic variables. Here we are not interested with understanding the relationship of demographic variables and response, we just want an accurate model to predict the response using the predictors. This is prediction.\n\nBut often we are interested to answer questions like: *Which media contribute to sales?*, *Which media generate the biggest boost in sales?*, or *How much increase in sales is associated with a given increase in* `TV` *advertising?*. This is inference.\n\nAnd sometimes we want a combination of both: *Values of homes based on crime rate, zoning, distance from a river, air quality, schools, size of houses etc.* and *How does air quality effect valeus of homes?*.\n\nWe use different models for prediction, inference, or combination of the two.\n\n### How Do We Estimate $f$?\n\nThere are many linear and non-linaer approaches we will discuss. But generally these models share certain characteristics. Here are they:\n\n-   We will always assume that we have observed a set of *n* different data points. These data points, observations, are called *training data*; which we will use these observations to train, or teach, our model on how to estimate $f$. Our training data will consist of $\\{(x_1,y_1), (x_2,y_2), \\dots, (x_n,y_n)\\}$, where $x_i = (x_{i1}, x_{i2}, \\dots, x_{ip})^T$\n\nWe want to apply a statistical learning method to the training data to estimate the unknown function $f$. We want to find a function $\\hat{f}$ such that $Y \\approx \\hat{f}(X)$ for any obsrvation $(X,Y)$.\n\nThese statistical learning methods can be charactarized as either *parametric* or *non-parametric*.\n\n**Parametric Methods**\n\nParametric methods involve a two step model-based approach:\n\n1.  *Select a model =\\> Make an assumption about the functional form of* $f$: is it linear, non linear?\n\nFor example a linear $f$ assumption would yield a *linear model*\n\n$$\n  f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p\n  $$ (2.4)\n\n2.  *Fit* or *train* the model\n\nAfter we select a model, we need a procedure that uses training data to *fit* or *train* the model.\n\nFor linear model, we need to estimate the parameters of the model ($\\beta_0, \\beta_1, \\dots, \\beta_p$). That is we want to find values of these parameters such that $$\n  Y \\approx \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p\n  $$ The most common approach to fitting the model (2.4) is called *ordinary least squares*. Chapter3. But there are other approaches as well.\n\nThis model-based approach is called *parametric:* we estimate $f$ via estimating a set of parameters.\n\nDisadvantage (potential): model we choose will usually not match the true unknown form of $f$ =\\> our estimates will be poor. =\\> solution: choose a *flexible* model that can fit different possible functional forms for $f$ =\\> you will need to estimate more parametrs =\\> *overfitting the data*.\n\n**Non-parametric Methods**\n\n=\\> No explicit assumptions about the functional form of $f$. The goal is to get an estimate of $f$ that gets as close to the data points as possible without being too rough or wiggly =\\> advantage over parametric approach: no assumption about the functional form of $f$--potentially accurately fit a wider range of possible shapes for $f$.\n\nDisadvantage =\\> lots of parameters to estimate =\\> very large of observations required to obtain an accurate estimate for $f$.\n\n### The Trade-Off Between Prediction Accuracy and Model Interpretability\n\nSome models are flexible some restrictive; in the sense that they can produce just a small range of functional forms to estimate $f$. Linear regression for instance is a relatively inflexible approach. Other metgods such as thin plate splines (non-parametric) are more flexible because they can generate a much wider range of possible functional forms to estimate $f$.\n\n*Why would be ever choose to use a more restrictive method instead of a very flexible approach?* :\n\n-   If we are mainly interested in inference, restrictive models are more interpretable. They give more information about each predictors effect on predicted.\n\n-   If we are mainly interested in prediction, flexible models give better fit. =\\> but may yield less accurate fits due to *overfitting!*\n\n### Supervised vs Unsupervised Learning\n\nMost statistical learning problems fall into these two categories: *supervised* or *unsupervised*.\n\nIn supervised learning for each observation of the predictor values $x_i, i = 1,\\dots, n$ there is an associated response value $y_i$. We wish to fit a model that relates the response to the predictors with the aims of either accurately predicting the response for future observations (prediction) or better understanding the relationship between the response and the predictors (inference). Linear regression, GAM, boosting, support vector machines operate in the supervised learning domain.\n\nUnsupervised leraning describes a situtaion in which for every observation $i=1,\\dots,n$ we obser a vector of values $x_i$ but no associated response $y_i$. We cannot use a linear regression model since we dont have $y_i$ values. Here we can seek to understand the relationships between the variables or between the observations; like *cluster analysis*, or clustering: to assert on the basis of $x_i,\\dots,x_n$ whether the observations fall into relatively distinct groups.\n\n## Regression vs Classisfication Problems\n\nVariables can be characterized as either *quantitative* or *qualitative*(also known as *categorical*). Quantitative varaibles take on numberical values: a person's age, height, or income, the value of a house, price of stock. Qualitative varaibles take on values n one of $K$ different *classes*, or categories: aperson's gender(male or female), the brand of a good (A,B, or C), a person's race etc.\n\nWe refer to problems with a quantitative response as *regression* problems, and probmes with a qualitative response as *classification* problems. However, the distinction is not clear-cut.\n\nLeast squares regression is used with a quantitative response, whereas logistic regression is typically used with a qualitative response. Some statistical methods, such as *K*-nearest negihbors and boosting, can be used in the case of either quantitative or qualitative.\n\nWe usually select statistical learning methods based on whether the response is quantitative or qualitative: we might use linear regression wjen quantitative and logistic regression when qualitative. But whether the *predictors* are qualitative or quantitative is usually not that important. Most of the statistical learning methods can be applied regardless of the predictor varible type.\n\n## Assessing Model Accuracy\n\nThere is no one method that dominates all others over all possible data sets. On a particular data set, one metghod may work best, but some other method may work better on a similar but differet data set. So it is important to assess the model accuracies of the methods.\n\nHere some ways to asses the model accuracy\n\n### Measuring the Quality of Fit\n\nSo, to evaluate the performance of a statistical learning method on a given data set, we need to measure how well its predictions actually match the observed data.\n\nIn the regression setting, the most commonly-used measure is the *mean squared error (MSE)*, given by\n\n$$\n\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{f}(x_i))^2\n$$\n\nMSE will be small if the predicted responses are veryt close to the true responses, and large if predicted and true responses differ substantially **on average**.\n\nHere since MSE is computed using the training data it is best to refer it as **training MSE**. But in general, we do not really care how well the method works on the training data =\\> *we are interested in the accuracy of the predictions that we obtain when we apply our method to previously unseen test data*.\n\nImagine: stock price prediction =\\> we have training and test data =\\> we already know the stock prices of the past, we dont care about the training data accuracy of the model, we want our model to predict the future prices of stocks best.\n\nOr we have blood characteristics of diabetes patients. We don't want our model to explain our existing patient's classification of diabetes or not, we want our model to predict our future patien's situation the best.\n\nMathematically:\n\nWe fit our statistical learning method on our training observations $\\{(x_1,y_1), (x_2,y_2), \\dots, (x_n,y_n)\\}$, and we obtain the estimate $\\hat{f}$. We can then compute $\\hat{f}(x_1),\\dots, \\hat{f}(x_n)$. If these are approximately equal to $y_1, \\dots, y_n$ then our training MSE will be small. Howeer, we are not interested in whether $y_i \\approx \\hat{f}(x_i)$, we want to know whether $\\hat{f}(x_0)$ is approximately equal to $y_0$, where $(x_0,y_0)$ is a *previously unseen test obsrevation not used to train the statistical learning method*.\n\nThat is, we want to choose the method that gives the lowest *test MSE*!.\n\nSo with our *test data* we can compute *test MSE*\n\n$$\n\\text{MSE}_{test} =\\frac{1}{n_{test}} \\sum(y_{test_{i}} - \\hat{f}(X_{test_i}))\n$$ (2.6)\n\nWe want the test MSE to be small as possible. We can compute test MSE via (2.6) if we have test data for different models and select the model with minimum test MSE.\n\nIf we don't have a test data, you might think our goal would be to minimize the training MSE since test and training data are colesly related. But no; minimal training MSE doesn't guarantee minimal training MSE\n\nUsually as the level of flexibility increases, the curves fit the observed data more closely =\\> lower training MSE. The level of flexibility is quantified by *degrees of freedom*. More restricted models have lower degrees of freedom. and usually the training MSE declines as flexibility increases.\n\n![](fig2.9.png)\n\nAs the flexibility of the statistical learning method increases, we observe a monotone decrease in the training MSE and a $U$-*shape* in the test MSE. This is a fundamental property of statistical learning that holds regardless of the particular data set at hand and regardless of the statistical method being used. AS model flexibility increases, training MSE will decrease, but the test MSE may not. When a given method yields a small training MSE but a large test MSE, we are said to be *overfitting* the data. This happens because our statistical learninig procedure is working too hard to find patterns in the training data, and may be picking up some patterns that are just caused by random change rather than by true properties of the unknown function $f$. When we overfit the trainin data, the test MSE will be very large because the supposed patterns that the method found in the training data simply don't exist in the test data.\n\nNote that regardless of whether or not overfitting has occured, we almost always expect the training MSE to be smaller than the test MSE because most statistical learning methods either directly or inderectly seek to mimizie the training MSE. Overfitting refers specifically to the case in which a less flexible model would have yielded a smaller test MSE.\n\nIn practice, training MSE is computed easily, but estimating test MSE is hard because usually no test data are available. We will learn approaches that can be used in practice to estimate the mininmum test MSE. One important method is *cross-validation*( Chapter 5), which is a method for estimating test MSE using the training data.\n\n### The Bias-Variance Trade-Off\n\nThe U-shape in the test MSE result of two competing properties of statistical learnig methods. The expected test MSE, for a given value $x_0$ can always be decomposed into sum of *variance* of $\\hat{f}(x_0)$, the squared *bias* of $\\hat{f}(x_0)$ and the variance of the error terms $\\epsilon$. That is\n\nThis means that to minimize the expected test error, we need to simultaneously have *low variance* and *low bias*. Since variance is always bigger than zero; $\\text{Var}(\\epsilon)$, and $\\text{Bias}(\\hat{f}(x_0))$ are nonnegative. So, the expected test MSE can never lie below $\\text{Var}(\\epsilon)$, the irreducible error from (2.3).\n\nWhat do we mean by the *variance* and *bias* of statistical learning method?\n\n*Varince* refers to the amount by which $\\hat{f}$ would change if we estimated it using a different training data set; different training data sets will result in a different $\\hat{f}$. But ideally, $\\hat{f}$ should not vary too much between training sets. If a method has high variance small changes in the training data can result in large changes in $\\hat{f}$.\n\nFlexible methods have hiher variance, because they fit better to the data points and changing any of the data points may cause the estiamte $\\hat{f}$ to chance considerably. But for example, least squares method is relatively inflexible and has low variance, because mooving any single observation will cause only a small shift in the position of the line.(2.9)\n\n*bias* refers to the error that is due to functional form of $\\hat{f}$. In real life, linear relationships are very rare. So performing linear regression will result in some bias in the estimate of $f$. If your $f$ is non-linear performing linear regression on different data sets will not produce an accurate estimate; so linear regression will result in high bias.\n\nFor example in 2.9 true $f$ is non linear; so linear regression have high bias, low variance. ![](fig2.10.png)\n\nIn 2.10 true $f$ is very close to linear, so linaer regression have low bias, low variance.\n\nGenerally more flexible methods result in less bias.\n\nAs a general rule, as we use more flexible methods the variance will increase and bias will decrease. The relative rate of change of these two quantities determines whether test MSE increases or decreases. As we increase the flexibility, the bias tends to initially decrease faster than the variance increases =\\> test MSE declines. However, at some point increasing flexibility has little impact on thebias but starts to significantly increase the variance =\\> test MSE increases.\n\n![](fig2.12.png)\n\nFigure 2.12 shows bias and variance effect to the test MSE for different $f$s. Horizontal dashed line represents $\\text{Var}(\\epsilon)$, the irreducible error; the red curve test MSE is the sum of squared bias, variance, and variance of irreducible error. In all cases bias decreases as flexibility increaes. However, the optimal flexibility is different for each $f$. In the left panel the bias initially decreaes rapidly, decreasing test MSE. In center panel true $f$ is closer to linear so there is only a small decrease in bias as flexibility increaes, and the test MSE only declines slightly before increasing rapidly as the variance increaes. Right hand panel, as flexibility increaess bias dramatically decreases because true $f$ is very non-linear. There is alsso very little increase in variance as flexibility increases =\\> tets MSE decreases before increasing.\n\nThis is called bias-variance trade off. Good test set performance of a method requires low variance as well as low squared bias. This is a trade off because it is easy to obtain a method with extremely low bias but high variance(for instance, drawing a curve that passes through every single training observation, or a method with low variance but high bias(by fitting a horizontal line to the data). Challange is finding a method wihch both the variance and squareed bias are low.\n\nIn real life, it is not possible to explicitly compute the test MSE, bias, or variance for methods. But we should keep this in mind.\n\n### The Classification Setting\n\nSo far we focused on regression setting. Problems such as bias-variance trade of also occurs in classification but in a modificated way because $y_i$ is no longer numerical.\n\nSuppose that we seek to estiamte $f$ on the basis of training observations $\\{(x_1,y_1), \\dots, (x_n,y_n)\\}$ where now $y_1,\\dots, y_n$ are qualitative.\n\nWe need to quantify the accuracy of our estimate $\\hat{f}$. We can use the training *error rate*, the proportion of mistakes that are made if we apply our estimate $\\hat{f}$ to the training observations:\n\n$$\n\\text{error rate}=\\frac{1}{n}\\sum^n_{i=1}I(y_i \\neq \\hat{y_i})\n$$ (2.8)\n\n$\\hat{y_i}$ is the predicted class label for the $i$th observation using $\\hat{f}$. $I(y_i \\neq \\hat{y_i})$ is an *indicator variable* that equals 1 if $y_i \\neq \\hat{y_i}$ and zero if ${y_i = \\hat{y_i}}$. If $I(y_i \\neq \\hat{y_i}) = 0$ then $i$th observation was classified correctly, otherwise it was misclassified. So (2.8) computes the fraction of incorrect classifications.\n\n(2.8) is *training error*. But as the regression setting we are more interested in *test error* rate. The *test error* rate associated with a set of test observations of the form\n\n$$\n\\text{error rate}_{test} = \\frac{1}{n_{test}}\\sum_{i=1}^{n_{test}}(I(y_{test_i} \\neq \\hat{y}_{test_i}))\n$$ (2.9)\n\nA *good* classifier is one for which the test error is smallest.\n\n**The Bayes Classifier**\n\nWe can minimize test error rate by a very simple classifier that *assigns each observation to the most likely class, given its predictor values*. In other words, we should simply assign a test observation with predictor vector $x_0$ to the class $j$ for which\n\n$$\nPr(Y = j | X = x_0)\n$$ (2.10)\n\nis largest. This is *conditional probability:* it is the probabilty that $Y=j$ given the observed predictor vector $x_0$. This classifier is called *Bayes classifier*.\n\nIn a two-class problem where there are only two possible response values, *class 1* or *class2*, the Bayes classifier corresponds to predicting class one if $Pr(Y=1 | X = x_0) > 0.5$, and class two otherwise.\n\nImagine having $X = (X_1, X_2)$. For each value of $X_1$ and $X_2$ there will be a different probability of the response being class 1 or 2. For $Pr(Y=class1 | X = (X_2,X_2)) > 0.5$ and $Pr(Y=class2 | X = (X_1,X_2))$.\n\nThe Bayes classifier produces the lowest possible test error rate, called the *Bayes error rate*. Since the Bayes classifer will always choose the class for which $Pr(Y = j | X = x_0)$ is largest, the error rate at $X=x_0$ will be $1-\\max_jPr(Y =j | X = x_0)$. In general, the overall Bayes error rate is given by\n\n$$\n\\text{Bayes error rate} = 1 - E(\\max_jPr(Y =j | X))\n$$ (2.11)\n\nwhere the expectation averages the probabilty over all possible values of X. The Bayes eror rate is analogous to the irreducible eror.\n\n**K-Nearest Neighbors**\n\nIn theory we always want to predict qualitative responses using the Bayes classifier. But for real data, we do not know the conditional distribution of $Y$ given $X$, and so computing the Bayes classfier is impossible. So Bayes classifier is like a gold standard to compare other methods.\n\nMany approaches attemp to estiamte the conditional distribution of $Y$ given $X$, and then classify a given observation to the class with highest *estimated* probability. One of them is *K-nearest neighbors*(KNN) classfier.\n\nGiven a positive integer *K* and a test observation $x_0$, the KNN clasffier first identifies the *K* points in the training data that are closest to $x_0$, represented by $N_0$. It then esitmates the conditional probability for class *j* as the fraction points in $N_0$ whose response values equal to $j$.\n\n$$\nPr(Y = j | X = x_0) = \\frac{1}{K}\\sum_{i \\in N_0}I(y_i=j)\n$$ (2.12)\n\nFinally, KNN applies Bayes rule and classifies the test observation $x_0$ to the class with the largest probability.\n\n![](fig2.14.png)\n\nFigure 2.14 provides an illustrative example of the KNN approach. Left panel =\\> Our goal is to make prediction for the black cross point. When $K=3$ KNN will identify the 3 oservations that are closest to the cross. There are two blue and one orange points; $Pr(Y=orange | X = x_{cross}) = 1/3$, and $Pr(Y=blue | X = x_{cross}) = 2/3$ =\\> KNN will predict that the black cross belongs to the blue class.\n\nThe choice of K is very important. as K increases flexibility decreases =\\> high bias, but low variance.\n\nJust like in regression setting there is not a strong relationship between the training error rate and the test error rate.\n\n![](fig2.17.png)\n\nas in the regression setting, the training error rate consistently declines as the flexibility($1/K$) increases. However, the test error rate again have a characteristic U-shape.\n\nIn both regression and classification settings, choosing the correct level of flexibility is critical. The bias-variance tradeoff =\\> U-shape in the test error, can make this a difficult task.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html_document","warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","highlight-style":"a11y","toc":true,"output-file":"Chapter2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","bibliography":["references.bib"],"sidebar":{"pinned":true,"align":"center"},"editor":"visual","theme":{"light":"minty","dark":"darkly"},"editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html_document","warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"a11y","output-file":"Chapter2.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"sidebar":{"pinned":true,"align":"center"},"editor":"visual","documentclass":"scrreprt","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}