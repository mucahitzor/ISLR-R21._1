<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8" />
<meta name="generator" content="quarto-1.3.433" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />


<title>ISLR-R21._1 – 2  Linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<!-- htmldependencies:E3FAD763 -->
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn"
      data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" 
      aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation"
      onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <h1 class="quarto-secondary-nav-title"></h1>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" 
      aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation"
      onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="/">
      ISLR-R21._1
      </a> 
        <div class="sidebar-tools-main tools-wide">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="/ISLR-R21._1.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="/ISLR-R21._1.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
    </div>
    <a href="https://twitter.com/intent/tweet?url=|url|" rel="" title="Twitter" class="quarto-navigation-tool px-1" aria-label="Twitter"><i class="bi bi-twitter"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/Chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>1</span>  <span class='chapter-title'>What Is Statistical Learning?</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/Chapter3.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class='chapter-number'>2</span>  <span class='chapter-title'>Linear Regression</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>3</span>  <span class='chapter-title'>Exercise</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="/Chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class='chapter-number'>4</span>  <span class='chapter-title'>Classification</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" ></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <div id="quarto-toc-target"></div>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>  <span class="chapter-title">Linear Regression</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>
<nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#simple-linear-regression" id="toc-simple-linear-regression"><span class="header-section-number">2.1</span> Simple Linear Regression</a>
  <ul>
  <li><a href="#estimating-the-coefficients" id="toc-estimating-the-coefficients"><span class="header-section-number">2.1.1</span> Estimating the coefficients</a></li>
  <li><a href="#assessing-the-accuracy-of-the-coefficient-estimates" id="toc-assessing-the-accuracy-of-the-coefficient-estimates"><span class="header-section-number">2.1.2</span> Assessing the Accuracy of the Coefficient Estimates</a></li>
  <li><a href="#assessing-the-accuracy-of-the-model" id="toc-assessing-the-accuracy-of-the-model"><span class="header-section-number">2.1.3</span> Assessing the Accuracy of the Model</a></li>
  </ul></li>
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression"><span class="header-section-number">2.2</span> Multiple Linear Regression</a>
  <ul>
  <li><a href="#estimating-the-regression-coefficients" id="toc-estimating-the-regression-coefficients"><span class="header-section-number">2.2.1</span> Estimating the Regression Coefficients</a></li>
  <li><a href="#some-important-questions" id="toc-some-important-questions"><span class="header-section-number">2.2.2</span> Some important Questions</a></li>
  </ul></li>
  <li><a href="#other-considerations-in-the-regression-model" id="toc-other-considerations-in-the-regression-model"><span class="header-section-number">2.3</span> Other Considerations in the Regression Model</a>
  <ul>
  <li><a href="#qualitative-predictors" id="toc-qualitative-predictors"><span class="header-section-number">2.3.1</span> Qualitative Predictors</a></li>
  <li><a href="#extensions-of-the-linear-model" id="toc-extensions-of-the-linear-model"><span class="header-section-number">2.3.2</span> Extensions of the Linear Model</a></li>
  <li><a href="#potential-problems" id="toc-potential-problems"><span class="header-section-number">2.3.3</span> Potential Problems</a></li>
  </ul></li>
  <li><a href="#selecting-best-regression-varaibles" id="toc-selecting-best-regression-varaibles"><span class="header-section-number">3</span> Selecting best regression varaibles</a>
  <ul>
  <li><a href="#identifying-influential-observations" id="toc-identifying-influential-observations"><span class="header-section-number">3.0.1</span> Identifying Influential observations</a></li>
  <li><a href="#testing-residuals-for-autocorrelation" id="toc-testing-residuals-for-autocorrelation"><span class="header-section-number">3.1</span> testing residuals for autocorrelation</a></li>
  <li><a href="#the-marketing-plan" id="toc-the-marketing-plan"><span class="header-section-number">3.2</span> The Marketing Plan</a></li>
  <li><a href="#comparison-of-linear-regression-with-k-nearest-neighbors" id="toc-comparison-of-linear-regression-with-k-nearest-neighbors"><span class="header-section-number">3.3</span> Comparison of Linear Regression with K-Nearest Neighbors</a></li>
  </ul></li>
  </ul>
</nav>
<p>We will predict quantitative response.</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggthemes)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjPlot)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magrittr)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dotwhisker)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hrbrthemes)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(showtext)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>extrafont<span class="sc">::</span><span class="fu">loadfonts</span>(<span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_ipsum_ps</span>(<span class="at">axis_title_size =</span> <span class="dv">11</span> , <span class="at">axis_title_just =</span> <span class="st">&quot;c&quot;</span>) <span class="sc">+</span> <span class="fu">theme</span>(<span class="at">axis.line =</span> <span class="fu">element_line</span>(<span class="at">color =</span><span class="st">&quot;black&quot;</span>)))</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb2"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>advertising <span class="ot">=</span> <span class="fu">read_csv</span>(<span class="st">&quot;./data/Advertising.csv&quot;</span>) <span class="sc">%&gt;%</span> as_tibble <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>advertising</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 200 × 4
      TV radio newspaper sales
   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;
 1 230.   37.8      69.2  22.1
 2  44.5  39.3      45.1  10.4
 3  17.2  45.9      69.3   9.3
 4 152.   41.3      58.5  18.5
 5 181.   10.8      58.4  12.9
 6   8.7  48.9      75     7.2
 7  57.5  32.8      23.5  11.8
 8 120.   19.6      11.6  13.2
 9   8.6   2.1       1     4.8
10 200.    2.6      21.2  10.6
# ℹ 190 more rows</code></pre>
</div>
</div>
<p>We are asked to suggest a marketing plan for next year which will yeild high product sales. We may want to inquire the following questions:</p>
<ol type="1">
<li><p><em>Is there a relationship between advertising budget and sales?</em></p>
<p>First we should determine if there is an association between adveritisng expenditure and sales. If not, no money shpuld be spent on advertising.</p></li>
<li><p><em>How strong is the relationship between advertising budget and sales?</em></p>
<p>If there is a relationship between advertising and sales, what is the strength of this relationship? Given a certain advertising budget, can we predict sales with a high level of accuracy? =&gt; strong relationsihp.</p></li>
<li><p><em>Which media contribute to sales?</em></p>
<p>Do all variables–tv,radio,newspaper– contribute to sales, or just one or the two?</p></li>
<li><p><em>How accurately can we estimate the effect of each medium on sales?</em></p>
<p>For every ollar spent on advertising in a particular medium, by what amount will sales increase? How accuretly can we predict this amount of increase?</p></li>
<li><p><em>How accurately can we predict future sales?</em></p>
<p>For any given level of media advertisig, what is our prediction for sales, and what is the accuracy of this prediciton?</p></li>
<li><p><em>Is the relationship linear?</em></p>
<p>If so linear regresion is appropriate tool, if not we may need to transform the predictor or the repsonse so that liner regression can be used.</p></li>
<li><p><em>Is there synergy among the advertising media?</em></p>
<p>Does the effect of a medium on sales depend on other medium levels? Does dividing advertisement budget to two or three medium yeild a higher sales?</p></li>
</ol>
<p>We can answer each of these questions using Linear regression.</p>
<section id="simple-linear-regression" class="level2" data-number="2.1">
<h2 data-number="2.1"><span class="header-section-number">2.1</span> Simple Linear Regression</h2>
<p>Predicting a quantitative response <span class="math inline">\(Y\)</span> on the basis of a single predictor variable <span class="math inline">\(X\)</span>.</p>
<p>Our assumption is that there is approximately a linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; we can write this linear relationship as</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 X_1 + \epsilon
\]</span></p>
<p><span class="math display">\[
Y \approx \beta_0 + \beta_1X
\]</span> (3.1)</p>
<p>For example lets say <span class="math inline">\(X\)</span> is <code>TV</code>, and <span class="math inline">\(Y\)</span> is <code>sales</code></p>
<p><span class="math display">\[
sales = \beta_0 + \beta_1 \times TV + \epsilon
\]</span> or</p>
<p><span class="math display">\[
sales = \beta_0 + \beta_1 \times TV
\]</span></p>
<p>On (3.1) <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown constants that represent the <em>intercept</em> and <em>slope</em> in the linear model. Together they are known as <em>coefficients</em> or <em>parameters</em>.</p>
<p>We are going to use or training data to produce estimates for <span class="math inline">\(\beta_0\)</span> =&gt; <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\beta_1\)</span> =&gt; <span class="math inline">\(\hat{\beta_1}\)</span>. Using these predicted coefficients we can predict sales;</p>
<p><span class="math display">\[
\hat{sales} = \hat{\beta_0} + \hat{\beta_1} \times TV
\]</span></p>
<p>or as in general form</p>
<p><span class="math display">\[
\hat{y} = \hat{\beta_0} + \hat{\beta_1}x
\]</span> (3.2)</p>
<section id="estimating-the-coefficients" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1"><span class="header-section-number">2.1.1</span> Estimating the coefficients</h3>
<p>Since, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are unknown, before we can use (3.1) to make predictions we must use data to estimate the coefficients. We have <span class="math inline">\(n\)</span> observations :</p>
<p><span class="math display">\[
(x_1,y_1), (x_2,y_2), \dots, (x_n,y_n)
\]</span></p>
<p>We want our estimated coefficients to give such predictions that will fit the avaible data as well =&gt; <span class="math inline">\(y_i \approx \hat{\beta_0} + \hat{\beta_1}x_i\)</span> for <span class="math inline">\(i = 1,\dots, n\)</span>. This coefficients will allow us to draw a regression line and we want this regression line to be close as possible to the <span class="math inline">\(n\)</span> data points we have.</p>
<p>There are different ways to measure <em>closeness</em>. The most common approach is minimizing the <em>least squares</em> criterion. Alternative approaches will be considered in Chapter 6.</p>
<p>Our predictions come from <span class="math inline">\(\hat{y_i} = \hat{\beta_0} + \hat{\beta_1}x_i\)</span>.</p>
<p>Then for each data we have a <em>residual</em>: difference between <span class="math inline">\(y\)</span> and <span class="math inline">\(\hat{y}\)</span>:</p>
<p><span class="math display">\[
e_i = y_i - \hat{y_i}
\]</span></p>
<p>We need to take the squares to get the distances–because of the negative residuals, and sum them to get the <em>residual sum of squares</em>(RSS)</p>
<p><span class="math display">\[
RSS = e_1^2 + e_2^2 + \dots + e_n^2
\]</span></p>
<p>this is equal to</p>
<p><span class="math display">\[
RSS = (y_i - \hat{beta_0} - \hat{\beta_1}x_1)^2 + (y_2 - \hat{\beta_0} - \hat{\beta_1}x_2) + \dots + (y_n - \hat{\beta_0} - \hat{\beta_1}x_n)
\]</span> (3.3)</p>
<p>The least squares approach chooses <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> to minimize RSS. These minimizers are</p>
<p><span class="math display">\[
\begin{align}
\hat{\beta_1} &amp;= \frac{\sum_{i=1}^n(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n(x_i - \bar{x})^2} \\
\hat{\beta_0} &amp;= \bar{y_i} - \hat{\beta_1}\bar{x}
\end{align}
\]</span> (3.4)</p>
<p><span class="math inline">\(\bar{y} = \frac{1}{n}\sum_{i=1}^ny_i\)</span> and <span class="math inline">\(\bar{x} = \frac{1}{n}\sum_{i=1}^nx_i\)</span> are the sample means.</p>
<p>So (3.4) defines the <em>least squares coefficient estimates</em> for simple linear regression.</p>
<p>Lets calculate them with R</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>beta_1_hat_adv <span class="ot">=</span> <span class="fu">sum</span>((advertising<span class="sc">$</span>TV <span class="sc">-</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>TV)) <span class="sc">*</span> ((advertising<span class="sc">$</span>sales <span class="sc">-</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>sales)))) <span class="sc">/</span> <span class="fu">sum</span>((advertising<span class="sc">$</span>TV <span class="sc">-</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>TV))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>beta_1_hat_adv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.04753664</code></pre>
</div>
</div>
<p>So; our $ = 0.0475 $</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>beta_0_hat_adv <span class="ot">=</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>sales) <span class="sc">-</span> beta_1_hat_adv <span class="sc">*</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>TV)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>beta_0_hat_adv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 7.032594</code></pre>
</div>
</div>
<p>our <span class="math inline">\(\hat{\beta_0} = 7.032\)</span></p>
<p>Lets compare them with r function</p>
<div class="cell">
<div class="sourceCode" id="cb8"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV, <span class="at">data =</span> advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.3860 -1.9545 -0.1913  2.0671  7.2124 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
TV          0.047537   0.002691   17.67   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.259 on 198 degrees of freedom
Multiple R-squared:  0.6119,    Adjusted R-squared:  0.6099 
F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Calculating the predicted values</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>y_hat_adv <span class="ot">=</span> beta_0_hat_adv <span class="sc">+</span> beta_1_hat_adv <span class="sc">*</span> advertising<span class="sc">$</span>TV</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>y_hat_adv[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 17.970775  9.147974  7.850224 14.234395 15.627218  7.446162  9.765950
 [8] 12.746498  7.441409 16.530414</code></pre>
</div>
</div>
<p>Our <span class="math inline">\(y_i\)</span> values are as above.</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>RSS <span class="ot">=</span> <span class="fu">sum</span>((advertising<span class="sc">$</span>sales <span class="sc">-</span> y_hat_adv)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>RSS</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2102.531</code></pre>
</div>
</div>
<p>Our <span class="math inline">\(\text{RSS} = 2102.531\)</span></p>
<p>So we can draw our regression line</p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>advertising <span class="sc">%&gt;%</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>TV, <span class="at">y =</span> sales) <span class="sc">+</span>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> beta_0_hat_adv, <span class="at">slope =</span> beta_1_hat_adv, <span class="at">color =</span> <span class="st">&quot;#262B70&quot;</span>, <span class="at">size =</span><span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">xend=</span>TV, <span class="at">yend=</span>y_hat_adv), <span class="at">color =</span> <span class="st">&quot;#939393&quot;</span>) <span class="sc">+</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">&quot;#AA1D2E&quot;</span>, <span class="at">size =</span><span class="dv">2</span>) <span class="sc">+</span> <span class="fu">theme_par</span>()</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="Chapter3_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="960" /></p>
<figcaption>For the advertising data, the least squares fit for the regression of sales onto TV. The fit is found by minimizing the sum of squared errors. Each grey line segment represents an error, adn the fit make a comprimise by averaging their squares. In this case a linear fit captures the essence of the relationship, although it is somewhat deficient in the left of the plot</figcaption>
</figure>
</div>
</div>
</div>
<p>So we have</p>
<p><span class="math display">\[
\hat{y_i} = 7.032 + 0.0475x_i
\]</span></p>
<p>According to this approximation an additional $1,000 spent on TV increases sales by 47.5 units.</p>
</section>
<section id="assessing-the-accuracy-of-the-coefficient-estimates" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2"><span class="header-section-number">2.1.2</span> Assessing the Accuracy of the Coefficient Estimates</h3>
<p>We assumed that <em>true</em> relationship is linear: <span class="math inline">\(Y = f(X) + \epsilon\)</span>. We don’t know <span class="math inline">\(f\)</span>, and <span class="math inline">\(\epsilon\)</span> is a mean-zero random error term.</p>
<p>We said <span class="math inline">\(f\)</span> is approximatly linear, so that <span class="math inline">\(f(X) = \beta_0 + \beta_1 X\)</span>; which means</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 X + \epsilon
\]</span> (3.5)</p>
<p>error term captures: * the true relationship may not be linear * other variables that affect Y * measurement error</p>
<p>and is independent of <span class="math inline">\(X\)</span>.</p>
<p>(3.5) is the <em>population regression line</em>: the best linar approximation to the true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p><span class="math display">\[
\hat{y} = \hat{\beta_0} + \hat{\beta_1}X
\]</span> is the <em>least squares line</em>. They are different of course! But we don’t know the population regression line. If we did:</p>
<p>For example, lets create a data;</p>
<ul>
<li>First we create random x values from 100 random numbers</li>
</ul>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out=</span><span class="dv">100</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] -2.000000 -1.959596 -1.919192 -1.878788 -1.838384 -1.797980 -1.757576
 [8] -1.717172 -1.676768 -1.636364</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">100</span>),<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> T)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>x[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] -0.6666667  0.2222222 -1.0303030 -1.3939394 -0.5454545  0.3838384
 [7] -1.5555556  1.3939394  1.4343434  0.4646465</code></pre>
</div>
</div>
<p>lets define our <span class="math inline">\(f\)</span>–population parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span></p>
<p><span class="math display">\[
f(X) = 2 + 3\times X
\]</span> Now lets create our <span class="math inline">\(Y\)</span> values from this function but we also want to add random error values as well</p>
<div class="cell">
<div class="sourceCode" id="cb19"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>y[<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>]</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] -0.5910311  2.6932610 -2.6074622 -3.5444715  1.5421255  2.2173638
 [7] -1.3430610  6.8067360  6.2573073  2.3898188</code></pre>
</div>
</div>
<p>So we have a data set</p>
<div class="cell">
<div class="sourceCode" id="cb21"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> y, <span class="at">x =</span> x</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<p>Now lets plot this data points</p>
<div class="cell">
<div class="sourceCode" id="cb22"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y) <span class="sc">+</span> <span class="fu">geom_point</span>() </span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Now, even though we already know <span class="math inline">\(f\)</span> and population parameters <span class="math inline">\(\beta_0 = 2\)</span> and <span class="math inline">\(\beta_1 = 3\)</span>, lets estimate them:</p>
<div class="cell">
<div class="sourceCode" id="cb23"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.01398 -0.65163 -0.06344  0.60455  2.39869 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.88077    0.09180   20.49   &lt;2e-16 ***
x            3.05893    0.07608   40.20   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9163 on 98 degrees of freedom
Multiple R-squared:  0.9428,    Adjusted R-squared:  0.9423 
F-statistic:  1616 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>So our <em>least squares estimation is</em></p>
<p><span class="math display">\[
\hat{y_i} = 1.88 + 3.06 x_i
\]</span> Lets draw this <em>least squares regression line to our plot</em></p>
<div class="cell">
<div class="sourceCode" id="cb25"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept=</span><span class="fl">1.88</span>, <span class="at">slope =</span> <span class="fl">3.06</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span> <span class="fu">theme_par</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>What about the population regression line</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fl">1.9</span>, <span class="at">slope =</span> <span class="fl">3.06</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">2</span>, <span class="at">slope =</span> <span class="dv">3</span>, <span class="at">color =</span><span class="st">&quot;red&quot;</span>) <span class="sc">+</span> <span class="fu">theme_par</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>They are not the same! If we were to have another data from the same data generation process other estimates of parameters would result with different <em>least squares regression lines</em>:</p>
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">111</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>x_r1 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">100</span>),<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> T)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>y_r1 <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x_r1 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1111</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>x_r2 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">100</span>),<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> T)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>y_r2 <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x_r2 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11111</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>x_r3 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">100</span>),<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> T)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>y_r3 <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x_r3 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">111111</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>x_r4 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">100</span>),<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> T)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>y_r4 <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x_r4 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1111111</span>)</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>x_r5 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">100</span>),<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> T)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>y_r5 <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x_r5 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">11111111</span>)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>x_r6 <span class="ot">=</span> <span class="fu">sample</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">100</span>),<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> T)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>y_r6 <span class="ot">=</span> <span class="dv">2</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>x_r6 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span></code></pre></div>
</div>
<p>Lets now estimate population parameters for each of these data and plot them</p>
<div class="cell">
<div class="sourceCode" id="cb28"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>data_r <span class="ot">=</span> <span class="fu">tibble</span>(</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  y_r1,x_r1,y_r2,x_r2,y_r3,x_r3,y_r4,x_r4, y_r5,x_r5,y_r6,x_r6</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>data_r</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 100 × 12
     y_r1   x_r1   y_r2    x_r2   y_r3   x_r3  y_r4   x_r4   y_r5    x_r5  y_r6
    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
 1  5.99   1.11   0.807 -0.263   8.82   1.80  -3.05 -1.52   7.64   1.68   6.49 
 2  6.53   1.35   3.74   0.141   6.23   1.92   5.11  1.27   8.71   2      7.75 
 3  6.28   1.31   2.16  -0.0202 -0.272 -0.707  2.39 -0.101  4.59   0.909  1.21 
 4  1.52  -0.141 -0.178 -0.990   5.45   0.788 -4.55 -1.84  -1.41  -1.11   0.478
 5  0.708 -1.03  -0.464 -0.586   0.361 -0.343 -3.31 -1.15   9.59   1.88   2.64 
 6  2.05   0.343  4.12   0.788  -1.09  -1.11  -5.13 -1.96   0.723 -0.586  4.10 
 7  4.54   0.747  5.44   1.60    0.479 -0.707  2.27  0.182  2.29  -0.263  3.68 
 8  1.69  -0.626  8.02   1.80   -2.23  -1.64   1.55  0.222 -1.45  -0.990  5.08 
 9  2.84   0.869  1.02   0.384   4.04   0.949  3.34 -0.747 -2.21  -0.828  8.33 
10 -0.933 -0.990  3.52   0.505  -0.471 -0.505 -1.07 -0.869  1.47   0.0606 2.45 
# ℹ 90 more rows
# ℹ 1 more variable: x_r6 &lt;dbl&gt;</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb30"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(x,y) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>)  <span class="sc">+</span> </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">lm</span>(y_r1 <span class="sc">~</span> x_r1)<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">lm</span>(y_r1 <span class="sc">~</span> x_r1)<span class="sc">$</span>coefficients[<span class="dv">2</span>], <span class="at">color =</span><span class="st">&quot;#29019F&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">lm</span>(y_r2 <span class="sc">~</span> x_r2)<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">lm</span>(y_r2 <span class="sc">~</span> x_r2)<span class="sc">$</span>coefficients[<span class="dv">2</span>], <span class="at">color =</span><span class="st">&quot;#0A04BF&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">lm</span>(y_r3 <span class="sc">~</span> x_r3)<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">lm</span>(y_r3 <span class="sc">~</span> x_r3)<span class="sc">$</span>coefficients[<span class="dv">2</span>], <span class="at">color =</span><span class="st">&quot;#0930DF&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">lm</span>(y_r4 <span class="sc">~</span> x_r4)<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">lm</span>(y_r4 <span class="sc">~</span> x_r4)<span class="sc">$</span>coefficients[<span class="dv">2</span>], <span class="at">color =</span><span class="st">&quot;#0E6DFF&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">lm</span>(y_r5 <span class="sc">~</span> x_r5)<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">lm</span>(y_r5 <span class="sc">~</span> x_r5)<span class="sc">$</span>coefficients[<span class="dv">2</span>], <span class="at">color =</span><span class="st">&quot;#2BA8FF&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fu">lm</span>(y_r6 <span class="sc">~</span> x_r6)<span class="sc">$</span>coefficients[<span class="dv">1</span>], <span class="at">slope =</span> <span class="fu">lm</span>(y_r6 <span class="sc">~</span> x_r6)<span class="sc">$</span>coefficients[<span class="dv">2</span>], <span class="at">color =</span><span class="st">&quot;#48D9FF&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span><span class="dv">2</span>, <span class="at">slope =</span><span class="dv">3</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_par</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>So, different data sets generated from the same true model result in slightly different least squares lines, but the unobserved population regression line does not change.</p>
<p>This is because we are using a sample, and estimating characteristics of the population. Usually these characteristics are different, but generally sample characteristics will provide a good estimate to the population characteristics.</p>
<p>Computing <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> from different sets of sample data provide different but similar results. And we are trying to estimate population parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> with these. Some of these <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> will overestimate, some will underestimate <span class="math inline">\(\beta_0\)</span>, and <span class="math inline">\(\beta_1\)</span>. But if we could average all these estimated parameters and take the average, than this average should be equal to population parameters; if this is the case this estimator is called <em>unbiased estimator</em>. So an unbiased estimator does not <em>systematically</em> over- or under-estimate the true parameter.</p>
<p>Okay but how close <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> are to the true values <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. We want to compute the standard errors associated with <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span>. Standard error telss us the average amount of estimate differes from the actual value.</p>
<p><span class="math display">\[
\begin{align}
\text{SE}(\hat{\beta_0})^2 &amp;= \sigma^2 \left[\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n(x_i - \bar{x}^2)}\right] \\
\text{SE}(\hat{\beta_1})^2 &amp;= \frac{\sigma^2}{\sum_{i=1}^n(x_i-\bar{x})^2}
\end{align}
\]</span> (3.8)</p>
<p>Where <span class="math inline">\(\sigma^2=\text{Var}(\epsilon)\)</span>.</p>
<p>Notice that formula of <span class="math inline">\(\text{SE}(\hat{\beta_1})\)</span> is smaller when <span class="math inline">\(x_i\)</span> are more spread out; intutively we have more <em>leverage</em> to estimate a slope when this is the case.</p>
<p>In general <span class="math inline">\(\sigma^2\)</span> is not known, but can be estimated from the data. The estimate of <span class="math inline">\(\sigma\)</span> is known as the <em>residual standard error</em>, and given by the formula</p>
<p><span class="math display">\[
\text{RSE} = \sqrt{\text{RSS}/(n-2)}
\]</span> So, when <span class="math inline">\(\sigma^2\)</span> is estimated fro mthe data we should write <span class="math inline">\(\hat{\text{SE}}(\hat{\beta_1})\)</span> to indicate that an estimate has been made, but usually we drop this extra hat.</p>
<p>Standard errors can be used to compute <em>confidence intervals</em>. A 95% confidence interval is defines as a range of values such that with 95% probability, the rage will contain the true unknown value of the parameter. The range is defined in terms of lower and upper limits computed from the sample of data. For linear regression, the 95% confidence interval for <span class="math inline">\(\beta_1\)</span> approximately takes the form</p>
<p><span class="math display">\[
\hat{\beta_1} \pm 1.96 \cdot \text{SE}(\hat{\beta_1})
\]</span> (3.9)</p>
<p>So there is approximately a 95% chance that the interval <span class="math display">\[[\hat{\beta_1} - 1.96 \cdot \text{SE}(\hat{\beta_1}), \hat{\beta_1} + 1.96 \cdot \text{SE}(\hat{\beta-1})]\]</span> (3.10) will contain the true value of <span class="math inline">\(\beta_1\)</span>. Same is true for <span class="math inline">\(\beta_0\)</span></p>
<p><span class="math display">\[
\hat{\beta_0} \pm 1.96 \cdot \text{SE}(\hat{\beta_0})
\]</span> (3.11)</p>
<p>Lets calculate the confidence intervals for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> from our original data and model</p>
<p><span class="math display">\[
\hat{sales_i} = \hat{\beta_0} + \hat{\beta_1}\cdot TV
\]</span> We first need to calculate RSS and RSE:</p>
<p><span class="math display">\[
\text{RSS} = \sum(y_i - \hat{y_i})^2
\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb31"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>RSS <span class="ot">=</span> <span class="fu">sum</span>((advertising<span class="sc">$</span>sales <span class="sc">-</span> y_hat_adv)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>RSS</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2102.531</code></pre>
</div>
</div>
<p><span class="math display">\[
\text{RSE} = \sigma = \sqrt{RSS/(n-2)}
\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>RSE <span class="ot">=</span> <span class="fu">sqrt</span>((RSS <span class="sc">/</span> (<span class="fu">length</span>(advertising<span class="sc">$</span>sales) <span class="sc">-</span><span class="dv">2</span>)))</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>RSE</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.258656</code></pre>
</div>
</div>
<p>For <span class="math inline">\(\beta_0\)</span></p>
<p><span class="math display">\[
\text{SE}(\hat{\beta_0}) = \sigma^2 \left[\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n(x_i - \bar{x})^2} \right]
\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb35"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>se_beta_0_adv <span class="ot">=</span>  <span class="fu">sqrt</span>(RSE<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span><span class="sc">/</span><span class="fu">length</span>(advertising<span class="sc">$</span>sales) <span class="sc">+</span> (<span class="fu">mean</span>(advertising<span class="sc">$</span>TV)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> <span class="fu">sum</span>((advertising<span class="sc">$</span>TV <span class="sc">-</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>TV))<span class="sc">^</span><span class="dv">2</span>))))</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>se_beta_0_adv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4578429</code></pre>
</div>
</div>
<p>So we can calculate the confidence interval for <span class="math inline">\(\beta_0\)</span></p>
<div class="cell">
<div class="sourceCode" id="cb37"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;In the absence of any advertising, sales will on average, fall somewhere between&quot;</span>,beta_0_hat_adv <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_0_adv, <span class="st">&quot;and&quot;</span>, beta_0_hat_adv <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_0_adv)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>In the absence of any advertising, sales will on average, fall somewhere between 6.135221 and 7.929966</code></pre>
</div>
</div>
<p>For <span class="math inline">\(\hat{\beta_1}\)</span>:</p>
<p><span class="math display">\[
\text{SE}(\hat{\beta_1})^2 =\frac{\sigma^2}{\sum(x_i - \bar{x})^2}
\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb39"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>se_beta_1_adv <span class="ot">=</span> <span class="fu">sqrt</span>(RSE<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (<span class="fu">sum</span>((advertising<span class="sc">$</span>TV <span class="sc">-</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>TV))<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>se_beta_1_adv</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.002690607</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;For each $1,000 increase in TV advertising, average increase in sales will be between&quot;</span>,(beta_1_hat_adv <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_1_adv) <span class="sc">*</span> <span class="dv">1000</span>, <span class="st">&quot;and&quot;</span>, (beta_1_hat_adv <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_1_adv)<span class="sc">*</span><span class="dv">1000</span>, <span class="st">&quot;by 95% confidence&quot;</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>For each $1,000 increase in TV advertising, average increase in sales will be between 42.26305 and 52.81023 by 95% confidence</code></pre>
</div>
</div>
<p>Lets confirm our results</p>
<div class="cell">
<div class="sourceCode" id="cb43"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.3860 -1.9545 -0.1913  2.0671  7.2124 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
TV          0.047537   0.002691   17.67   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.259 on 198 degrees of freedom
Multiple R-squared:  0.6119,    Adjusted R-squared:  0.6099 
F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb45"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 2.5 %     97.5 %
(Intercept) 6.12971927 7.93546783
TV          0.04223072 0.05284256</code></pre>
</div>
</div>
<p>So standard errors of our estimated parameters tells us the average amount of difference from the true population parameters. And using the confidence intervals we can tell a range of the true population parameters’ interval with a percentage (usually 95%).</p>
<p>Lets do this for our <code>data</code> as well, which we know has the form</p>
<p><span class="math display">\[
y_i = 2 + 3 x_i + \epsilon_i
\]</span> Lets calculate <span class="math inline">\(\hat{\beta_0}\)</span> and <span class="math inline">\(\hat{\beta_1}\)</span> first</p>
<div class="cell">
<div class="sourceCode" id="cb47"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>beta_1_hat_data <span class="ot">=</span> <span class="fu">sum</span>((data<span class="sc">$</span>x <span class="sc">-</span> <span class="fu">mean</span>(data<span class="sc">$</span>x)) <span class="sc">*</span> (data<span class="sc">$</span>y <span class="sc">-</span> <span class="fu">mean</span>(data<span class="sc">$</span>y))) <span class="sc">/</span> <span class="fu">sum</span>((data<span class="sc">$</span>x <span class="sc">-</span> <span class="fu">mean</span>(data<span class="sc">$</span>x))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>beta_1_hat_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.058925</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb49"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>beta_0_hat_data <span class="ot">=</span> <span class="fu">mean</span>(data<span class="sc">$</span>y) <span class="sc">-</span> beta_1_hat_data <span class="sc">*</span> <span class="fu">mean</span>(data<span class="sc">$</span>x)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>beta_0_hat_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.880772</code></pre>
</div>
</div>
<p><span class="math display">\[
\hat{y_i} = 1.88 + 3.05 x_i
\]</span></p>
<p>lets confirm this</p>
<div class="cell">
<div class="sourceCode" id="cb51"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y<span class="sc">~</span>x, data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x, data = data)

Coefficients:
(Intercept)            x  
      1.881        3.059  </code></pre>
</div>
</div>
<p>Lets calculate the residual sum of squares, residual sum of errors, standard errors, and confidence intervals</p>
<div class="cell">
<div class="sourceCode" id="cb53"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> beta_0_hat_data <span class="sc">+</span> beta_1_hat_data <span class="sc">*</span> x</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>  ) <span class="ot">-&gt;</span> data</span></code></pre></div>
</div>
<div class="cell">
<div class="sourceCode" id="cb54"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>RSS_data <span class="ot">=</span> <span class="fu">sum</span>((data<span class="sc">$</span>y <span class="sc">-</span> data<span class="sc">$</span>y_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>RSS_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 82.28514</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb56"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>RSE_data <span class="ot">=</span> <span class="fu">sqrt</span>((RSS_data<span class="sc">/</span>(<span class="fu">length</span>(data<span class="sc">$</span>y) <span class="sc">-</span><span class="dv">2</span>)))</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>RSE_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9163211</code></pre>
</div>
</div>
<p>so <span class="math inline">\(\sigma_{data} = 0.9163\)</span></p>
<p>We can now compute the standard errors of estiamed coefficients</p>
<div class="cell">
<div class="sourceCode" id="cb58"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>se_beta_0_data <span class="ot">=</span> <span class="fu">sqrt</span>(((<span class="dv">1</span><span class="sc">/</span><span class="fu">length</span>(data<span class="sc">$</span>y)) <span class="sc">+</span> (<span class="fu">mean</span>(data<span class="sc">$</span>x)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> <span class="fu">sum</span>((data<span class="sc">$</span>x <span class="sc">-</span> <span class="fu">mean</span>(data<span class="sc">$</span>x))<span class="sc">^</span><span class="dv">2</span>))) <span class="sc">*</span> RSE_data<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>se_beta_0_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.09179903</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb60"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>se_beta_1_data <span class="ot">=</span> <span class="fu">sqrt</span>(RSE_data<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> (<span class="fu">sum</span>((data<span class="sc">$</span>x <span class="sc">-</span> <span class="fu">mean</span>(data<span class="sc">$</span>x))<span class="sc">^</span><span class="dv">2</span>)))</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>se_beta_1_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.07608457</code></pre>
</div>
</div>
<p>Lets confirm</p>
<div class="cell">
<div class="sourceCode" id="cb62"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x,data))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ x, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.01398 -0.65163 -0.06344  0.60455  2.39869 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.88077    0.09180   20.49   &lt;2e-16 ***
x            3.05893    0.07608   40.20   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9163 on 98 degrees of freedom
Multiple R-squared:  0.9428,    Adjusted R-squared:  0.9423 
F-statistic:  1616 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>So we can say that on average our <span class="math inline">\(\hat{\beta_0}\)</span>s are 0.091 differ from <span class="math inline">\(\beta_0\)</span>, and our <span class="math inline">\(\hat{\beta_1}\)</span>s differ 0.076 from <span class="math inline">\(\beta_1\)</span>. To make more sense of it we can calculate the confidence intervals</p>
<div class="cell">
<div class="sourceCode" id="cb64"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;By 95% confidence we can say that the true beta_0 is between&quot;</span>, beta_0_hat_data <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_0_data, <span class="st">&quot;and&quot;</span>, beta_0_hat_data <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_0_data )</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>By 95% confidence we can say that the true beta_0 is between 1.700846 and 2.060698</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb66"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;By 95% confidence we can say that the true beta_0 is between&quot;</span>, beta_1_hat_data <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_1_data, <span class="st">&quot;and&quot;</span>, beta_1_hat_data <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_beta_1_data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>By 95% confidence we can say that the true beta_0 is between 2.909799 and 3.208051</code></pre>
</div>
</div>
<p>Lets confirm this</p>
<div class="cell">
<div class="sourceCode" id="cb68"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x,data))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>               2.5 %   97.5 %
(Intercept) 1.698600 2.062944
x           2.907938 3.209912</code></pre>
</div>
</div>
<p>Lets plot this confidence interval</p>
<div class="cell">
<div class="sourceCode" id="cb70"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y<span class="sc">~</span>x,data) <span class="sc">%&gt;%</span> </span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dwplot</span>(<span class="at">ci =</span> <span class="fl">0.95</span>,<span class="at">dot_args =</span> <span class="fu">list</span>(<span class="at">size=</span><span class="dv">2</span>), <span class="at">vline =</span> <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;grey50&quot;</span>, <span class="at">linetype =</span><span class="dv">2</span>))</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-40-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Since standard error tells us the range of the <span class="math inline">\(\beta\)</span> values via confidence interval, we can infer that if this range does not include 0, than our <span class="math inline">\(\beta\)</span> values are statistically significant; x is assocaited with y.</p>
<p>Lets do this for <code>advertising</code> data as well</p>
<div class="cell">
<div class="sourceCode" id="cb71"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span> TV, advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dwplot</span>(<span class="at">ci =</span> <span class="fl">0.95</span>,<span class="at">dot_args =</span> <span class="fu">list</span>(<span class="at">size=</span><span class="dv">2</span>), <span class="at">vline =</span> <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;grey50&quot;</span>, <span class="at">linetype =</span><span class="dv">2</span>))</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="Chapter3_files/figure-html/unnamed-chunk-41-1.png" class="img-fluid" width="672" /></p>
<figcaption>the 95% confidence interval does not include 0; TV is statistically significant</figcaption>
</figure>
</div>
</div>
</div>
<p>Or we can use standard erros to perform <em>hypothesis tests</em> on the coefficients. We usually don’t care about the intercept, so lets do the hypothesis test on only <span class="math inline">\(\hat{\beta_1}\)</span>.</p>
<p><span class="math display">\[
\begin{align}
H_0 &amp;: \beta_1 = 0 \to \text{there is no relationship between X and Y} \\
H_1 &amp;: \beta_1 \neq 0 \to \text{there is some relationship between X and Y}
\end{align}
\]</span> If the <em>null-hypothesis</em> is true =&gt; $ _1 = 0$ =&gt; <span class="math inline">\(Y = \beta_0 + \epsilon\)</span> =&gt; <span class="math inline">\(X\)</span> is not associated with <span class="math inline">\(Y\)</span>.</p>
<p>To test the null-hypothessi, we need to determine whether our estimate <span class="math inline">\(\hat{\beta_1}\)</span> is sufficiently far from zero that we can be confident that <span class="math inline">\(\beta_1\)</span> is non-zero. How far is enough? This depends on the accuracy of <span class="math inline">\(\hat{\beta_1}\)</span>–that is it depends on <span class="math inline">\(\text{SE}(\hat{\beta_1})\)</span>. If <span class="math inline">\(\text{SE}(\hat{\beta_1})\)</span> is small, then even relatively small values of <span class="math inline">\(\hat{\beta_1}\)</span> may provide strong evidence that <span class="math inline">\(\beta_1 \neq 0\)</span>. If <span class="math inline">\(\text{SE}(\hat{\beta_1})\)</span> is large, then <span class="math inline">\(\hat{\beta_1}\)</span> must be large in absolute value in order for us to reject the null hypothessis. In practice we compute a <em>t-statistic</em> given by</p>
<p><span class="math display">\[
t = \frac{\hat{\beta_1} - 0}{\text{SE}(\hat{\beta_1})}
\]</span> (3.14)</p>
<p>which measures the number of standard deviations that <span class="math inline">\(\hat{\beta_1}\)</span> is away from zero. From the t-statistic we can compute the <em>p-value</em>; a small p value indicates that it is unlikely to observe such a substantial association between the predictor and the response due to chance, in absence of any real association between the predictor and the response. So if p value is small we infer that there is assocaition between the predictor and the response =&gt; we reject the null hypothesis. Typical p-value cutoffs for rejecting the null hypothesis are 5 or 1%. When <span class="math inline">\(n=30\)</span> these correspond to tstatsitcs of around 2 and 2.75.</p>
<div class="cell">
<div class="sourceCode" id="cb72"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.3860 -1.9545 -0.1913  2.0671  7.2124 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
TV          0.047537   0.002691   17.67   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.259 on 198 degrees of freedom
Multiple R-squared:  0.6119,    Adjusted R-squared:  0.6099 
F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb74"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales<span class="sc">~</span>TV,advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">confint</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>  kableExtra<span class="sc">::</span><span class="fu">kable</span>(<span class="at">format =</span> <span class="st">&quot;latex&quot;</span>)</span></code></pre></div>
<div class="cell-output-display">

</div>
</div>
<p>Here we see that t statistics are very high, and p values are very low =&gt; reject the null hypothesis for both <span class="math inline">\(\beta\)</span> values; they are statistically significant.</p>
</section>
<section id="assessing-the-accuracy-of-the-model" class="level3" data-number="2.1.3">
<h3 data-number="2.1.3"><span class="header-section-number">2.1.3</span> Assessing the Accuracy of the Model</h3>
<p>Once we concluded the statistically significant variable–rejecting the null hypothesis, we want to quantify <em>the extend to which the model fits the data</em>. We can use either</p>
<ul>
<li><em>Residual standard error</em></li>
<li><span class="math inline">\(R^2\)</span></li>
</ul>
<p><em>Residual standard error</em></p>
<p>Recall from <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)</span> that associated with each observation is an error term <span class="math inline">\(\epsilon\)</span>. Because of these error terms even if we knew the true regression line, we would not be able to predict <span class="math inline">\(Y\)</span> from <span class="math inline">\(X\)</span>. The <em>RSE</em> is an estimate of the standard deviation of <span class="math inline">\(\epsilon\)</span>. It is the average amount that the response will deviate from the true regression line, computed by</p>
<p><span class="math display">\[
\begin{align}
\text{RSE} &amp;= \sqrt{\frac{1}{n-2}\text{RSS}} \\
&amp;= \sqrt{\frac{1}{n-2}\sum_{i=1}^n(y_i - \hat{y_i})^2}
\end{align}
\]</span> (3.15)</p>
<p>In the advertising data, RSE was 3.26; actual sales in each market deviate from the true regression line by approximately 3,269 units, on average. This also means that; if the model were correct and the true values of the unknown coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> were known exaclty, any predcition of sales on the basis of TV advertising would still be off by about 3,260 units on average. Is this prediction error accaptable? Depends on the data: in the <code>advertising</code> data set the mean value of <code>sales</code> is <span class="math inline">\(\approx 14,000\)</span> units, and so the percentage error is <span class="math inline">\(3,260 / 14,000 = 23%\)</span>.</p>
<p>The RSE is considered a measure of the <em>lack of fit</em> of the model <span class="math inline">\(Y=\beta_0 + \beta_1 + \epsilon\)</span> to the data. If the predictions from the model are very close to the true outcome values–<span class="math inline">\(\hat{y_i} \approx y_i\)</span> then RSE will be small, and we can concldue that the model fits the data very well. Otherwise, if <span class="math inline">\(\hat{y_i}\)</span> is very far from <span class="math inline">\(y_i\)</span> then RSE may be quite large, indicating the model doesn’t fit the data well.</p>
<p><span class="math inline">\(R^2\)</span><strong>Statistic</strong></p>
<p>The RSE provides an absolute measure of lack of fit of the model to the data. <span class="math inline">\(R^2\)</span> provides an alternative measure of fit. It takes the form of a <em>proportion</em>–the proportion of variance explained–and so its always <span class="math inline">\(0\leq R^2 \leq 1\)</span> and is independent of the scale of <span class="math inline">\(Y\)</span>–as opposed to RSE.</p>
<p><span class="math display">\[
R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS}
\]</span> (3.17)</p>
<p>where <span class="math inline">\(\text{TSS} = \sum(y_i - \bar{y})^2\)</span> is the <em>total sun of squares</em> and <span class="math inline">\(\text{RSS} = \sum(y_i - \hat{y_i})^2\)</span>. TSS measures the total variaance in the response <span class="math inline">\(Y\)</span>; and can be thought of as the amount of varaiblity ingerent in the response before the regression is performed. RSS measures the amount of varaiblity that is left unexplained after performing the regression. So TSS - RSS measures the amount of variability in the response that is explained by performing the regression, and <span class="math inline">\(R^2\)</span> measures the <em>proportion of variability in</em> <span class="math inline">\(Y\)</span> <em>that can be explained using</em> <span class="math inline">\(X\)</span>. As <span class="math inline">\(R^2\)</span> gets closer to 1, a large proportion of the variability in the response has been explained by the regression. A number near 0 indicates that the regression did not explain much of the variablity in the response; this might occur because the linear model is wrong, or the inherit error <span class="math inline">\(\sigma^2 = \text{RSE}^2\)</span> is high, or both.</p>
<p>Lets calculate <span class="math inline">\(R^2\)</span> of our estimation on <code>advertising</code> data with the model <span class="math inline">\(\hat{sales_i} = \hat{\beta_0} + \hat{\beta_1}TV_i\)</span></p>
<div class="cell">
<div class="sourceCode" id="cb75"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>advertising <span class="sc">%&gt;%</span> </span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">sales_hat =</span> beta_0_hat_adv <span class="sc">+</span> beta_1_hat_adv <span class="sc">*</span> TV) <span class="ot">-&gt;</span> advertising</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>advertising</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 200 × 5
      TV radio newspaper sales sales_hat
   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;
 1 230.   37.8      69.2  22.1     18.0 
 2  44.5  39.3      45.1  10.4      9.15
 3  17.2  45.9      69.3   9.3      7.85
 4 152.   41.3      58.5  18.5     14.2 
 5 181.   10.8      58.4  12.9     15.6 
 6   8.7  48.9      75     7.2      7.45
 7  57.5  32.8      23.5  11.8      9.77
 8 120.   19.6      11.6  13.2     12.7 
 9   8.6   2.1       1     4.8      7.44
10 200.    2.6      21.2  10.6     16.5 
# ℹ 190 more rows</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb77"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>RSS <span class="ot">=</span> <span class="fu">sum</span>((advertising<span class="sc">$</span>sales <span class="sc">-</span> advertising<span class="sc">$</span>sales_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>RSS</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2102.531</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb79"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>RSE <span class="ot">=</span> <span class="fu">sqrt</span>(RSS<span class="sc">/</span>(<span class="fu">length</span>(advertising<span class="sc">$</span>sales) <span class="sc">-</span><span class="dv">2</span>))</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>RSE</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 3.258656</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb81"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>TSS <span class="ot">=</span> <span class="fu">sum</span>((advertising<span class="sc">$</span>sales <span class="sc">-</span> <span class="fu">mean</span>(advertising<span class="sc">$</span>sales))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>TSS</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 5417.149</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb83"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>R2 <span class="ot">=</span> (TSS <span class="sc">-</span> RSS) <span class="sc">/</span> TSS</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>R2</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6118751</code></pre>
</div>
</div>
<p>61% of the variablity in <code>sales</code> is explained by a linear regression on <code>TV</code>.</p>
<p>what about our <code>data</code></p>
<div class="cell">
<div class="sourceCode" id="cb85"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 100 × 3
        y      x  y_hat
    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
 1 -0.591 -0.667 -0.159
 2  2.69   0.222  2.56 
 3 -2.61  -1.03  -1.27 
 4 -3.54  -1.39  -2.38 
 5  1.54  -0.545  0.212
 6  2.22   0.384  3.05 
 7 -1.34  -1.56  -2.88 
 8  6.81   1.39   6.14 
 9  6.26   1.43   6.27 
10  2.39   0.465  3.30 
# ℹ 90 more rows</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb87"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>RSS_data <span class="ot">=</span> <span class="fu">sum</span>((data<span class="sc">$</span>y <span class="sc">-</span> data<span class="sc">$</span>y_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>RSS_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 82.28514</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb89"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>RSE_data <span class="ot">=</span> <span class="fu">sqrt</span>(RSS_data<span class="sc">/</span>(<span class="fu">length</span>(data<span class="sc">$</span>y) <span class="sc">-</span><span class="dv">2</span>))</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>RSE_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9163211</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb91"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>TSS_data <span class="ot">=</span> <span class="fu">sum</span>((data<span class="sc">$</span>y <span class="sc">-</span> <span class="fu">mean</span>(data<span class="sc">$</span>y))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>TSS_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1439.473</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb93"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>R2_data <span class="ot">=</span> (TSS_data <span class="sc">-</span> RSS_data) <span class="sc">/</span> TSS_data</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>R2_data</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9428366</code></pre>
</div>
</div>
<p>94% of the variablity in <code>y</code> is explained by <code>x</code>; very good fit of the model.</p>
<p><span class="math inline">\(R^2\)</span> is better to interpret than RSE.</p>
</section>
</section>
<section id="multiple-linear-regression" class="level2" data-number="2.2">
<h2 data-number="2.2"><span class="header-section-number">2.2</span> Multiple Linear Regression</h2>
<p>In practice we have more than one predictor to explain <span class="math inline">\(Y\)</span>.</p>
<p>How can we extend our analysis of the advertising order to accomodate the other two (<code>radio</code> and <code>newspaper</code>) additional predictors?</p>
<p>=&gt; We can run three separate simple linear regressions, each of which uses a different advertising medium as a predictor:</p>
<div class="cell">
<div class="sourceCode" id="cb95"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.3860 -1.9545 -0.1913  2.0671  7.2124 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
TV          0.047537   0.002691   17.67   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.259 on 198 degrees of freedom
Multiple R-squared:  0.6119,    Adjusted R-squared:  0.6099 
F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb97"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> radio, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ radio, data = advertising)

Residuals:
     Min       1Q   Median       3Q      Max 
-15.7305  -2.1324   0.7707   2.7775   8.1810 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  9.31164    0.56290  16.542   &lt;2e-16 ***
radio        0.20250    0.02041   9.921   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.275 on 198 degrees of freedom
Multiple R-squared:  0.332, Adjusted R-squared:  0.3287 
F-statistic: 98.42 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb99"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ newspaper, data = advertising)

Residuals:
     Min       1Q   Median       3Q      Max 
-11.2272  -3.3873  -0.8392   3.5059  12.7751 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 12.35141    0.62142   19.88  &lt; 2e-16 ***
newspaper    0.05469    0.01658    3.30  0.00115 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 5.092 on 198 degrees of freedom
Multiple R-squared:  0.05212,   Adjusted R-squared:  0.04733 
F-statistic: 10.89 on 1 and 198 DF,  p-value: 0.001148</code></pre>
</div>
</div>
<p>We find that on average, $1,000 increase in spending on radio advertising is associated with an increase in sales by around 203 units.</p>
<p>We find that on average, $1,000 increase in spending on newspaper advertising is associated with an increase in sales by around 55 units.</p>
<p>We find that on average, $1,000 increase in spending on TV advertising is associated with an increase in sales by around 47 units.</p>
<p><strong>However</strong> this approach is not good. First of all it is unclear to make a sinlge prediction of sales given levesl of the three advertising media budgets, since each has their own regression equation. Second, each of these three regression equations ignores the other two medi in forming estimates for the regression coefficients. Especially if these media budgets are correalted, this can lead to very misleading estimates of the individaul media effects on sales.</p>
<p>Instead of the seperate linear regressions for each predictor, better approach is to extend the simple linear regression setting <span class="math inline">\(Y = \beta_0 + \beta_1 X\)</span> to</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_p X_p + \epsilon
\]</span></p>
<p>(3.19)</p>
<p>Here we interpret <span class="math inline">\(B_j\)</span> as the average effect of a one unit increase in <span class="math inline">\(X_j\)</span>, <em>holding all other predictors fixed</em>.</p>
<p>For the advertising example;</p>
<p><span class="math display">\[
sales = \beta_0 + \beta_1 TV + \beta_2 radio + \beta_3 newspaper + \epsilon
\]</span></p>
<section id="estimating-the-regression-coefficients" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1"><span class="header-section-number">2.2.1</span> Estimating the Regression Coefficients</h3>
<p>Again, regression coefficients in (3.19) are unknown, and must be estimated from the data. And with these estimates we can make predictions</p>
<p><span class="math display">\[
\hat{y_i} = \hat{\beta_0} + \hat{\beta_1}x_1 + \hat{\beta_2}x_2 + \dots + \hat{\beta_p}x_p
\]</span> (3.21)</p>
<p>The parameters are estimated using the same least squares approach with simple linear regression. We choose <span class="math inline">\(\beta_0, \beta_1, \dots, \beta_p\)</span> to minimize the sum of squared residuals</p>
<p>$$ <span class="math display">\[\begin{align}

\text{RSS} &amp;= \sum_{i = 1}^n(y_i - \hat{y_i})^2 \\
&amp;= \sum_{i = 1}^n(y_i - \hat{\beta_0} - \hat{\beta_1}x_{i1} - \beta_2x_{i2} - \dots - \beta_px_{ip})^2

\end{align}\]</span> $$ (3.22)</p>
<p><span class="math inline">\(\hat{\beta_0}, \hat{\beta_1},\dots, \hat{\beta_p}\)</span> values minimize RSS.</p>
<p>We are not going to calculate these estimates with our hands, R does that.</p>
<p>Lets see our model results with the three predictors.</p>
<div class="cell">
<div class="sourceCode" id="cb101"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio + newspaper, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.8277 -0.8908  0.2418  1.1893  2.8292 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
TV           0.045765   0.001395  32.809   &lt;2e-16 ***
radio        0.188530   0.008611  21.893   &lt;2e-16 ***
newspaper   -0.001037   0.005871  -0.177     0.86    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.686 on 196 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 
F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><em>Interpretation:</em> for a given amount of Tv and newspaper advertising, spending additional $1,000 on radio(TV)(newspaper) advertising leads to an increase in sales approximately by 189(46)(-1) units.</p>
<p>If we compare these effects with one predictor regressions</p>
<blockquote>
<p>We find that on average, $1,000 increase in spending on radio advertising is associated with an increase in sales by around 203 units.</p>
</blockquote>
<blockquote>
<p>We find that on average, $1,000 increase in spending on newspaper advertising is associated with an increase in sales by around 55 units.</p>
</blockquote>
<blockquote>
<p>We find that on average, $1,000 increase in spending on TV advertising is associated with an increase in sales by around 47 units.</p>
</blockquote>
<p>For tv and radio coefficients are similar, but for <strong>newspaper</strong>: from the simple linear regression coefficient of newspaper was significant, but in multiple linear regression it is not; p value is very high.</p>
<div class="cell">
<div class="sourceCode" id="cb103"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  2.5 %     97.5 %
(Intercept)  2.32376228 3.55401646
TV           0.04301371 0.04851558
radio        0.17154745 0.20551259
newspaper   -0.01261595 0.01054097</code></pre>
</div>
</div>
<p>Its confidence interval contains 0.</p>
<p>This difference between simple linear regression and multiple linear regression coefficients stems from the fact that in the simple regression, the slope term represents the average effet of a one dollar increase in newspaper advertising, ignoring other preditors such as tv and radio. In contrsat, in the multiple regression setting, the coefficient for newspaper represents the average effect of increeasing newapper spending by one dollar, while holding tv and radio fixed.</p>
<p>Does it make sense for the multiple regression to suggest no relationship between sales and newspaper while the simple linear regression implies the opposite? Yes!</p>
<p>Take a look at this correlation matrix:</p>
<div class="cell">
<div class="sourceCode" id="cb105"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(advertising[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>])</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  TV      radio  newspaper     sales
TV        1.00000000 0.05480866 0.05664787 0.7822244
radio     0.05480866 1.00000000 0.35410375 0.5762226
newspaper 0.05664787 0.35410375 1.00000000 0.2282990
sales     0.78222442 0.57622257 0.22829903 1.0000000</code></pre>
</div>
</div>
<p>We can also make it a plot out of this:</p>
<div class="cell">
<div class="sourceCode" id="cb107"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot</span>(<span class="fu">cor</span>(advertising[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]), <span class="at">method =</span> <span class="st">&quot;number&quot;</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-60-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Notice that correlation between radio and newspaper is 0.35. This reveals a tendency to spend more on newspaper advertising in markets where more is spent on radio advertising. Now suppose the multiple regression is correct and newspaper advertising has no direct impact on sales, but radio advertising does increase sales. Then in markets where we spend more on radio, our sales will tend to be higher, adn as our correaltion matrix shows, we also tend to spend more on newspaper advertising in those same markets. Hence, in a simple linaer regresion which only examines sales vs newspaper, we will observe that higher values of newspaper tend to be associated with higher values of sales, even though newspaper advertising does not actually affect sales. So newspaper sales are proxy for radio advertising; newspaper gets credit for the effect of radio on sales.</p>
<p>This is a very common issue. Consider running a regression of shark attack versus ice cream sales for data collected at a given beach community. We would see a positive relationship, similar to that seen between sales and newspaper. Of course ice creams doesnt cause shark attacks. In reality higher temperatures cause more people to visit the beach in trun results in more ice cream sales and more shark attacks. A multiple regression of attacks versus ice cream sales and temperature revals that, the former predictr is no longer significant after adjusting for temperature.</p>
</section>
<section id="some-important-questions" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2"><span class="header-section-number">2.2.2</span> Some important Questions</h3>
<p>When we perform MLR, we usually are interested answering a few important questions</p>
<ol type="1">
<li><p><em>Is at least one of the predictors</em> <span class="math inline">\(x_1, x_2, \dots, x_p\)</span> <em>useful in predicting the response?</em></p></li>
<li><p><em>Do all predictors help to explain</em> <span class="math inline">\(Y\)</span>, <em>or is only a subset of the predictors useful?</em></p></li>
<li><p><em>How well does the model fit the data?</em></p></li>
</ol>
<p>4 <em>Given a set of predictor values, what response value should we predict, and how accurate is our prediction?</em></p>
<p>Lets answer these questions:</p>
<ol type="1">
<li><p><em>Is at least one of the predictors</em> <span class="math inline">\(x_1, x_2, \dots, x_p\)</span> <em>useful in predicting the response?</em></p>
<p>In SLR we simply checked whether <span class="math inline">\(\beta_1 = 0\)</span> or not. In MLR, we need to ask whether all of the regression coefficients are zero <span class="math inline">\(\beta_1 = \beta_2 = \dots = \beta_p = 0\)</span>. So our null hypothesis is</p>
<p><span class="math display">\[
\begin{align}
H_0 &amp;: \beta_1 = \beta_2 = \dots = \beta_o = 0 \\
H_\alpha &amp;: \text{at least one} \space B_j \space \text{is non-zero}
\end{align}
\]</span> This hypothesis test is performed by computing the <em>F-statistic</em>,</p>
<p><span class="math display">\[
F = \frac{(TSS - RSS)/p}{RSS/(n-p-1)}
\]</span> (3.23)</p>
<p>So, if there is no relationship between the resposne and predictors, we expect F-statistic to take on value close to 1. if <span class="math inline">\(H_\alpha\)</span> is true then <span class="math inline">\(F\)</span> should be greater than 1.</p></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb108"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio + newspaper, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.8277 -0.8908  0.2418  1.1893  2.8292 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
TV           0.045765   0.001395  32.809   &lt;2e-16 ***
radio        0.188530   0.008611  21.893   &lt;2e-16 ***
newspaper   -0.001037   0.005871  -0.177     0.86    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.686 on 196 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 
F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>F statistic is 570 and is far from 1. But it is best to have a look at the p-value of the F statistic which is also very small.</p>
<p>This means that at least one of the media is associated with increase sales.</p>
<p>In (3.23) we are testing <span class="math inline">\(H_0\)</span> that all the coefficients are zero. Sometimes we want to test that a particular subset of <span class="math inline">\(q\)</span> of the coefficients are zero. This corresponesd to a null hypothesis</p>
<p><span class="math display">\[
  H_0 : \beta_{p-q+1} = \beta_{p-q+2} = \dots = \beta_p
  \]</span></p>
<p>In this case we fit a second model that uses all the variables <em>except</em> those last <span class="math inline">\(q\)</span>. suppose that residual sum of squares for that model is <span class="math inline">\(RSS_0\)</span>. Then the appropriate F-statistic is</p>
<p><span class="math display">\[
  F = \frac{(RSS_0 - RSS)/q}{RSS/(n-p-1)}
  \]</span> (3.24)</p>
<p>On advertising MLR we saw that newspaper is not significant from its p value. Then why do we need to look at the overall F-statistic? after all, it seems likely that if any one of the p-values for the individual variables is very small, then <em>at least one of the predictors is realted to the respose</em>. This is not true usually, especially when <span class="math inline">\(p\)</span> is large.</p>
<p>So after estimating the model first look at the F-statistic, than to the individual t statistic p values.</p>
<ol start="2" type="1">
<li><p><em>Do all predictors help to explain</em> <span class="math inline">\(Y\)</span>, <em>or is only a subset of the predictors useful?</em> =&gt; <strong>Deciding on important variables</strong></p>
<p>After lookig at the F statistic, we can look at the individual p values. But if *p$ is large, we are going to make false discoveries.</p>
<p>Usually not all predictors are associated with the response. This task of determining which predictors are associated with the response in order to fit a single model involving only those predictors is refered to as <em>variable selection</em>. Check out Chapter 6 for more detail. But here is a breif outline of some of the classical approaches.</p>
<p>Ideally we want to perform variable selection by trying out a lot of different models, each containing different subset of the predictors. For instance if our <span class="math inline">\(p=2\)</span> then we can consider four models</p>
<ul>
<li><ol type="1">
<li>a model containing no variables</li>
</ol></li>
<li><ol start="2" type="1">
<li>a model containing <span class="math inline">\(x_1\)</span> only</li>
</ol></li>
<li><ol start="3" type="1">
<li>a model containnig <span class="math inline">\(x_2\)</span> only</li>
</ol></li>
<li><ol start="4" type="1">
<li>a model containing <span class="math inline">\(x1\)</span> and <span class="math inline">\(x_2\)</span>.</li>
</ol></li>
</ul>
<p>We can then select the <em>best</em> model out of all the models by looking at some statistics we can use to judge the quality of the model. These are</p>
<ul>
<li><em>Mallow</em>’s <span class="math inline">\(C_p\)</span></li>
<li><em>Akaike information creterion</em> (AIC)</li>
<li><em>Bayesian information criterion</em>(BIC)</li>
<li><em>adjusted</em> <span class="math inline">\(R^2\)</span></li>
</ul>
<p>These are discussed in more detail in chapter 6.</p>
<p>We can also determine which model is the best by plotting various model outputs, such as the residuals, in order to search for patterns.</p>
<p>But we cannot consider all models, especially when <span class="math inline">\(p\)</span> is high. There are three classical approaches for this task:</p>
<ul>
<li><em>Forward selection</em>
<ul>
<li><p>begin with <em>null model</em> a model that contains an intercept but no predictors.</p></li>
<li><p>Then fit <em>p</em> simple linear regressions and add to the null model the variable that results in the lowest RSS.</p></li>
<li><p>Then add to that model the variable that results in the lowest RSS for the new two-variable model. This approach is continued until some stopping rule is satisfied.</p></li>
</ul></li>
<li><em>Backward selection</em>
<ul>
<li>Put all varaibles in the model.</li>
<li>remove the least statistically significant predictor.</li>
<li>estimate the new regression with <span class="math inline">\(p-1\)</span> variable, remove the largest p-value predictor. This procedure continues until a stopping rule is reached =&gt; stop after all remaining variables have p value &lt; 0.02</li>
</ul></li>
<li><em>Mixed selection</em>
<ul>
<li>Combination of forward selection and backward selection</li>
<li>Start with no variables in the model</li>
<li>add the varaible that provides the best fit</li>
<li>add varaibles one-by-one</li>
<li>at one point if the p-value for one of the variables in the model rises above a certain treshold, then we remove that variabel from the model.</li>
<li>Continue untill all variables have sufficiently low p value, and all vairables in the model woudl have a large p-value if added to the model</li>
</ul></li>
</ul>
<p>Backwar slecetion cannot be used if <span class="math inline">\(p&gt;n\)</span>, forward selection can always be used.</p></li>
<li><p><em>How well does the model fit the data?</em> <strong>Model Fit</strong></p></li>
</ol>
<p>Two of the most common numerical measures of model fit are RSE and <span class="math inline">\(R^2\)</span>.</p>
<p>In SLR <span class="math inline">\(R^2\)</span> is equal to <span class="math inline">\(cor(Y,X)\)</span>. In MLR <span class="math inline">\(R^2 = cor(Y,\hat{Y})\)</span>.</p>
<p><span class="math inline">\(R^2\)</span> will always increase as you add more variable, even though that varaible is not statistically significant. This is because adding another variable must allow us to fit the trainig data(not necessarly test data) more accurately. But this increase in <span class="math inline">\(R^2\)</span> after adding a statistically not-significant varible is very low =&gt; evidence that you can drop the not significant variable. Check out the <span class="math inline">\(R^2\)</span> variables of the following models</p>
<div class="cell">
<div class="sourceCode" id="cb110"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio + newspaper, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.8277 -0.8908  0.2418  1.1893  2.8292 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
TV           0.045765   0.001395  32.809   &lt;2e-16 ***
radio        0.188530   0.008611  21.893   &lt;2e-16 ***
newspaper   -0.001037   0.005871  -0.177     0.86    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.686 on 196 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 
F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb112"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>They are almost the same.</p>
<p>But lets see the <span class="math inline">\(R^2\)</span> of the model containing only Tv</p>
<div class="cell">
<div class="sourceCode" id="cb114"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.3860 -1.9545 -0.1913  2.0671  7.2124 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 7.032594   0.457843   15.36   &lt;2e-16 ***
TV          0.047537   0.002691   17.67   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.259 on 198 degrees of freedom
Multiple R-squared:  0.6119,    Adjusted R-squared:  0.6099 
F-statistic: 312.1 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>it is 0.611.</p>
<p>If we add radio</p>
<div class="cell">
<div class="sourceCode" id="cb116"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>It increaes dramatically. This implies that model that uses TV and radio to predict sales is better than only using Tv. also radio is statistically signifiacnt.</p>
<div class="cell">
<div class="sourceCode" id="cb118"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + newspaper, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.6231 -1.7346 -0.0948  1.8926  8.4512 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 5.774948   0.525338  10.993  &lt; 2e-16 ***
TV          0.046901   0.002581  18.173  &lt; 2e-16 ***
newspaper   0.044219   0.010174   4.346 2.22e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.121 on 197 degrees of freedom
Multiple R-squared:  0.6458,    Adjusted R-squared:  0.6422 
F-statistic: 179.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Not with newspaper though.</p>
<p>Or the opposite</p>
<div class="cell">
<div class="sourceCode" id="cb120"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> radio, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ radio, data = advertising)

Residuals:
     Min       1Q   Median       3Q      Max 
-15.7305  -2.1324   0.7707   2.7775   8.1810 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  9.31164    0.56290  16.542   &lt;2e-16 ***
radio        0.20250    0.02041   9.921   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.275 on 198 degrees of freedom
Multiple R-squared:  0.332, Adjusted R-squared:  0.3287 
F-statistic: 98.42 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb122"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales<span class="sc">~</span>radio<span class="sc">+</span>TV, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ radio + TV, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb124"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> radio <span class="sc">+</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ radio + newspaper, data = advertising)

Residuals:
     Min       1Q   Median       3Q      Max 
-15.5289  -2.1449   0.7315   2.7657   7.9751 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 9.188920   0.627672  14.640   &lt;2e-16 ***
radio       0.199045   0.021870   9.101   &lt;2e-16 ***
newspaper   0.006644   0.014909   0.446    0.656    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.284 on 197 degrees of freedom
Multiple R-squared:  0.3327,    Adjusted R-squared:  0.3259 
F-statistic: 49.11 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>What about RSE:</p>
<div class="cell">
<div class="sourceCode" id="cb126"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb128"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio + newspaper, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.8277 -0.8908  0.2418  1.1893  2.8292 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
TV           0.045765   0.001395  32.809   &lt;2e-16 ***
radio        0.188530   0.008611  21.893   &lt;2e-16 ***
newspaper   -0.001037   0.005871  -0.177     0.86    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.686 on 196 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 
F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>adding newspaper increased the RSE =&gt; no need to add newspaper. Adding newspaper increases RSE because</p>
<p><span class="math display">\[
RSE = \sqrt{\frac{1}{n-p-1}RSS}
\]</span></p>
<p>Models with more variables can have higher RSE if the decrease in RSS is small relative to the increase in <span class="math inline">\(p\)</span>.</p>
<p>So we can look at both the RSE and <span class="math inline">\(R^2\)</span>.</p>
<p><strong>Four: Predictions</strong></p>
<p>After fitting the model we can predict <span class="math inline">\(Y\)</span> =&gt; <span class="math inline">\(\hat{y}\)</span> with estimated coefficients. However, there are three sorts of uncertainty associated with this prediction:</p>
<ol type="1">
<li><p>The coefficient esstimates <span class="math inline">\(\hat{\beta_0}, \hat{\beta_1},\dots,\hat{\beta_p}\)</span> are estimates for <span class="math inline">\(\beta_0, \beta_1, \dots, \beta_p\)</span>:</p>
<p>That is, the <em>least squares plane</em></p></li>
</ol>
<p><span class="math display">\[
\hat{y} = \hat{\beta_0} + \hat{\beta_1}x_1 + \dots +  \hat{\beta_p}x_p
\]</span></p>
<p>which is only an estimate for the <em>true population regression plane</em> <span class="math display">\[
f(X) = \beta_0 + \beta_1x_1 + \dots + \beta_px_p
\]</span></p>
<p>So there is an inaccuracy in the coefficient estimates =&gt; this is the <em>reducible error</em> from Chapter 2. We can compute a <em>confidence interval</em> to determine how close <span class="math inline">\(\hat{y}\)</span> will be to <span class="math inline">\(f(X)\)</span>.</p>
<ol start="2" type="1">
<li><p>Assuming a linear model for <span class="math inline">\(f(X)\)</span> is almost always an aaproximation of reality (usually relationships are not linear), so ther is an additional source of potentially reducible error =&gt; this is the <em>model bias</em>.</p>
<p>When we are using a linear model, we are in fact estimating the best linear approximation to the true surface. However, we will ignore this discrepancy and operate as if the linear model is correct</p></li>
<li><p>Even if we knew <span class="math inline">\(f(X)\)</span>–that is even if we knew the true values of <span class="math inline">\(\beta\)</span>–the response value cannot be predicted perfectly because of the random error <span class="math inline">\(\epsilon\)</span> in the model =&gt; <em>irreducable error</em>. How much will <span class="math inline">\(Y\)</span> vary from <span class="math inline">\(\hat{y}\)</span> =&gt; we use <em>prediction intervals</em> to answer this question.</p>
<p>Predicion intervals are always wider than confidence intervals, because they contain both the <em>reducible error</em>(error from estimating coefficients of <span class="math inline">\(f(X)\)</span>) and irreducible error.</p></li>
</ol>
<p>We use a <em>confidence interval</em> to quantify the uncertainty surrounding the <em>average</em> <code>sales</code> over a large number of cities. For example given that $100,000 is spent on <code>TV</code> advertising and $20,000 is spent on <code>radio</code> advertising in each city, the 95% confidence interval is <span class="math inline">\([10,985, 11,528]\)</span>. We interpret this to mean that 95% of intervals of this form will contain the true value of <span class="math inline">\(f(X)\)</span>.</p>
<p>On the other hand, <em>a prediction interval</em> can be used to quantify the uncertainty surrounding <code>sales</code> for a <em>particular</em> city. Given that $100,000 is spent on <code>TV</code> advertising and $20,000 is spent on <code>radio</code> advertising in that city the 95% prediction interval is <span class="math inline">\([7,930, 14,580]\)</span>. We interpret this to mean that 95% of intervals of this form will contain the true value of <span class="math inline">\(Y\)</span> for this city. Note that both intervals are centered at 11,256, but that the prediction intervaş is substantially wider than the confidence interval, reflecting the increased uncertainty about <code>sales</code> for a given city in comparison to the average <code>sales</code> over many locations.</p>
</section>
</section>
<section id="other-considerations-in-the-regression-model" class="level2" data-number="2.3">
<h2 data-number="2.3"><span class="header-section-number">2.3</span> Other Considerations in the Regression Model</h2>
<section id="qualitative-predictors" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1"><span class="header-section-number">2.3.1</span> Qualitative Predictors</h3>
<p>In practice not all variables are <em>quantitative</em>; some predictors are <em>qualitative</em>.</p>
<p>Check out the <code>Credit</code> data set</p>
<div class="cell">
<div class="sourceCode" id="cb130"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="ot">=</span> <span class="fu">read.csv</span>(<span class="st">&quot;./data/Credit.csv&quot;</span>) <span class="sc">%&gt;%</span> as_tibble</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>Credit</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 400 × 12
      ID Income Limit Rating Cards   Age Education Gender   Student Married
   &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;  
 1     1   14.9  3606    283     2    34        11 &quot; Male&quot;  No      Yes    
 2     2  106.   6645    483     3    82        15 &quot;Female&quot; Yes     Yes    
 3     3  105.   7075    514     4    71        11 &quot; Male&quot;  No      No     
 4     4  149.   9504    681     3    36        11 &quot;Female&quot; No      No     
 5     5   55.9  4897    357     2    68        16 &quot; Male&quot;  No      Yes    
 6     6   80.2  8047    569     4    77        10 &quot; Male&quot;  No      No     
 7     7   21.0  3388    259     2    37        12 &quot;Female&quot; No      No     
 8     8   71.4  7114    512     2    87         9 &quot; Male&quot;  No      No     
 9     9   15.1  3300    266     5    66        13 &quot;Female&quot; No      No     
10    10   71.1  6819    491     3    41        19 &quot;Female&quot; Yes     Yes    
# ℹ 390 more rows
# ℹ 2 more variables: Ethnicity &lt;chr&gt;, Balance &lt;int&gt;</code></pre>
</div>
</div>
<p>Lets do a scatterplot of all variables</p>
<div class="cell">
<div class="sourceCode" id="cb132"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="fu">where</span>(is.numeric)) <span class="sc">%&gt;%</span> <span class="fu">pairs</span>(.)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="Chapter3_files/figure-html/unnamed-chunk-73-1.png" class="img-fluid" width="672" /></p>
<figcaption>Fig 3.6 The credit data set contains infortmation about blaance, age, cards, education income, limit and rating for a number of potential customers</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>Predictors with Only Two Levels</strong></p>
<p>We want to investigate differences in credit card balance between maels and females, ignoring other variables for the moment. If a qualitative predictors (also known as <em>factor</em>) only has two <em>levels</em>, then incorporating it into a regression model is very simple. We create a <em>dummy variable</em> that takes on two possible <em>numerical</em> values. For example based on <code>Gender</code> varaible, we can create a new varaible that takes the form</p>
<p><span class="math display">\[
x_i =
\begin{cases}
1 &amp; \text{if}\space i\text{th} \space\text{person is female} \\
0 &amp; \text{if}\space i\text{th} \space\text{person is male}
\end{cases}
\]</span> (3.26)</p>
<p>and use this variable as a predictor in the regression equation. This results in the model</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1x_i + \epsilon_i =
\begin{cases}
\beta_0 + \beta_1 + \epsilon_i &amp; i\text{th} \space\text{person is female} \\
\beta_0 + \epsilon_i &amp; i\text{th} \space\text{person is male}
\end{cases}
\]</span> (3.27)</p>
<p>Now <span class="math inline">\(\beta_0\)</span> can be interpreted as the average credit card balance among males, <span class="math inline">\(\beta_0 + \beta_1\)</span> as the average credit card among females, and <span class="math inline">\(\beta_1\)</span> as the average difference in credit card balance between females and males.</p>
<p>Here is the regression results:</p>
<div class="cell">
<div class="sourceCode" id="cb133"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a>Credit<span class="sc">$</span>Gender <span class="ot">&lt;-</span> <span class="fu">factor</span>(Credit<span class="sc">$</span>Gender, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot; Male&quot;</span>,<span class="st">&quot;Female&quot;</span>))</span>
<span id="cb133-2"><a href="#cb133-2" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb133-3"><a href="#cb133-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb133-4"><a href="#cb133-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb133-5"><a href="#cb133-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Balance <span class="sc">~</span> Gender, Credit) <span class="sc">%&gt;%</span> </span>
<span id="cb133-6"><a href="#cb133-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb133-7"><a href="#cb133-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = Balance ~ Gender, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-529.54 -455.35  -60.17  334.71 1489.20 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    509.80      33.13  15.389   &lt;2e-16 ***
GenderFemale    19.73      46.05   0.429    0.669    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 460.2 on 398 degrees of freedom
Multiple R-squared:  0.0004611, Adjusted R-squared:  -0.00205 
F-statistic: 0.1836 on 1 and 398 DF,  p-value: 0.6685</code></pre>
</div>
</div>
<p>R converts all <em>“Female”</em> values to 1 automatically. If we were to do this manually</p>
<div class="cell">
<div class="sourceCode" id="cb135"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> </span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Gender =</span> <span class="fu">as.character</span>(Gender)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Gender =</span> <span class="fu">ifelse</span>(Gender <span class="sc">==</span> <span class="st">&quot;Female&quot;</span>,<span class="dv">1</span>,<span class="dv">0</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(Balance <span class="sc">~</span> Gender, .) <span class="sc">%&gt;%</span> </span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Balance ~ Gender, data = .)

Residuals:
    Min      1Q  Median      3Q     Max 
-529.54 -455.35  -60.17  334.71 1489.20 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   509.80      33.13  15.389   &lt;2e-16 ***
Gender         19.73      46.05   0.429    0.669    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 460.2 on 398 degrees of freedom
Multiple R-squared:  0.0004611, Adjusted R-squared:  -0.00205 
F-statistic: 0.1836 on 1 and 398 DF,  p-value: 0.6685</code></pre>
</div>
</div>
<p>This means that average credit card debt for males is estimated to be $509.80, whereas females are estimated to carry $19.73 in additional debt for a total of <span class="math inline">\(\$509.80 + \$19.73 = \$529.53\)</span>. However, the coefficient of the dummy variable is not significant; there is no statistical evidence of a difference in average credit card balance between the genders.</p>
<div class="cell">
<div class="sourceCode" id="cb137"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> </span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>Gender, <span class="at">y =</span>Balance, <span class="at">fill =</span> Gender) <span class="sc">+</span> <span class="fu">geom_boxplot</span>(<span class="at">show.legend =</span> F) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">data =</span>(Credit <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(Gender) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">Balance =</span> <span class="fu">mean</span>(Balance))),<span class="at">shape =</span> <span class="dv">4</span>, <span class="at">show.legend =</span> F) <span class="sc">+</span> <span class="fu">theme_clean</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-76-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>The desicion to code females as 1 and males as 0 in (3.27) is arbitrary, and has no effect on the regression fit, but does alter the interpretation of the coefficients. If we had coded males as 1 and females as 0:</p>
<div class="cell">
<div class="sourceCode" id="cb138"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> </span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Gender =</span> <span class="fu">factor</span>(Gender, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Female&quot;</span>, <span class="st">&quot; Male&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb138-3"><a href="#cb138-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(Balance <span class="sc">~</span> Gender,.) <span class="sc">%&gt;%</span> </span>
<span id="cb138-4"><a href="#cb138-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Balance ~ Gender, data = .)

Residuals:
    Min      1Q  Median      3Q     Max 
-529.54 -455.35  -60.17  334.71 1489.20 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   529.54      31.99  16.554   &lt;2e-16 ***
Gender Male   -19.73      46.05  -0.429    0.669    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 460.2 on 398 degrees of freedom
Multiple R-squared:  0.0004611, Adjusted R-squared:  -0.00205 
F-statistic: 0.1836 on 1 and 398 DF,  p-value: 0.6685</code></pre>
</div>
</div>
<p>Then we would say that estimated average debt for females is $529.54, and for males is <span class="math inline">\(\$529.52 - \$19.73 = \$509.80\)</span>.</p>
<p>Alternatively, instead of 0/1 coding scheme, we could create a dummy variable</p>
<p><span class="math display">\[
x_i =
\begin{cases}
1 &amp; \text{if}\space i\text{th}\space \text{person is female} \\
-1 &amp; \text{if}\space i\text{th}\space \text{person is male}
\end{cases}
\]</span> and use this variable in the regression equation. This results in the model</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1x_i + \epsilon_i =
\begin{cases}
\beta_0 + \beta_1 + \epsilon_i &amp; \text{if}\space i\text{th}\space \text{person is female} \\
\beta_0 - \beta_1 + \epsilon_i &amp; \text{if}\space i\text{th}\space \text{person is male}
\end{cases}
\]</span> Now <span class="math inline">\(\beta_0\)</span> can be interpreted as the overall average credit card balance (ignoring the gender effect), and <span class="math inline">\(\beta_1\)</span> is the amount that females are above the average and males are below the average.</p>
<div class="cell">
<div class="sourceCode" id="cb140"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> </span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Gender =</span> <span class="fu">as.character</span>(Gender)) <span class="sc">%&gt;%</span> </span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Gender =</span> <span class="fu">ifelse</span>(Gender <span class="sc">==</span> <span class="st">&quot;Female&quot;</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(Balance <span class="sc">~</span> Gender,.) <span class="sc">%&gt;%</span> </span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Balance ~ Gender, data = .)

Residuals:
    Min      1Q  Median      3Q     Max 
-529.54 -455.35  -60.17  334.71 1489.20 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  519.670     23.026  22.569   &lt;2e-16 ***
Gender         9.867     23.026   0.429    0.669    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 460.2 on 398 degrees of freedom
Multiple R-squared:  0.0004611, Adjusted R-squared:  -0.00205 
F-statistic: 0.1836 on 1 and 398 DF,  p-value: 0.6685</code></pre>
</div>
</div>
<p>Now <span class="math inline">\(\beta_0\)</span> is $ 519.670 which is the halfway between the male and female averages of $509.80 and $529.53. The estimate for <span class="math inline">\(\beta_1\)</span> is $9.865, which is half of $19.74, the average difference between females and males.</p>
<p><strong>Qualitative Predictors with More than Two levels</strong></p>
<p>In this case we need to create an additional dummy. For example have a look at the <code>Ethnicity</code> variable</p>
<div class="cell">
<div class="sourceCode" id="cb142"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> <span class="fu">select</span>(Ethnicity) <span class="sc">%&gt;%</span> <span class="fu">unique</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 3 × 1
  Ethnicity       
  &lt;chr&gt;           
1 Caucasian       
2 Asian           
3 African American</code></pre>
</div>
</div>
<p>Has three possible values. Then we need to create two dummies</p>
<p><span class="math display">\[
x_{i1} =
\begin{cases}
1 &amp; \text{if}\space i\text{th}\space \text{person is Asian} \\
0 &amp; \text{if}\space i\text{th}\space \text{person is not Asian}
\end{cases}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
x_{i2} =
\begin{cases}
1 &amp; \text{if}\space i\text{th}\space \text{person is Caucasian} \\
0 &amp; \text{if}\space i\text{th}\space \text{person is not Caucasian}
\end{cases}
\]</span></p>
<p>Then both these varaibles can be used in the regression equation, in order to obtain the model</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \epsilon_i =
\begin{cases}
\beta_0 + \beta_1 + \epsilon_i &amp; \text{if}\space i\text{th}\space \text{person is Asian} \\
\beta_0 + \beta_2 + \epsilon_i &amp; \text{if}\space i\text{th}\space \text{person is Caucasian} \\
\beta_0 + \epsilon_i &amp; \text{if}\space i\text{th}\space \text{person is African American}
\end{cases}
\]</span> Now <span class="math inline">\(\beta_0\)</span> can be interpreted as the average credit card balance for African Americans, <span class="math inline">\(\beta_1\)</span> can be interpreted as the difference in the average balance between Asian and African american categories, and <span class="math inline">\(\beta_2\)</span> can be interpreted as the difference in average balance between the Caucasian and African American categories.</p>
<div class="cell">
<div class="sourceCode" id="cb144"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Balance <span class="sc">~</span> Ethnicity, Credit) <span class="sc">%&gt;%</span> </span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb144-6"><a href="#cb144-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = Balance ~ Ethnicity, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-531.00 -457.08  -63.25  339.25 1480.50 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)          531.00      46.32  11.464   &lt;2e-16 ***
EthnicityAsian       -18.69      65.02  -0.287    0.774    
EthnicityCaucasian   -12.50      56.68  -0.221    0.826    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 460.9 on 397 degrees of freedom
Multiple R-squared:  0.0002188, Adjusted R-squared:  -0.004818 
F-statistic: 0.04344 on 2 and 397 DF,  p-value: 0.9575</code></pre>
</div>
</div>
<p>There will always be one fewer dummy variable than the number of levels. The level with no dummy variable–African American in this example–is known as the <em>baseline</em>.</p>
<p>From the regression results we see that the estimated <code>balance</code> for the baseline, African American, is $531.00. It is estimated that Asian category will have $18.69 less debt than the African American category on average, and the Caucasian category will have $12.50 less debt that the African American category. However, p-values associated with the coefficient estimates for the two dummy variables are very large, suggesting no statistical evidence of a real difference in credit card balance between the ethnicities. The coefficients will change bassed on the baseline and coding.</p>
<p>Rather than relying on the individual coefficients, we can use F-test to test <span class="math inline">\(H_0 : \beta_1 = \beta_2 = 0\)</span>; this does not depend on the coding. The F-test has a p-value of 0.9575, indicating that we cannot reject the null hypothesis that there is no relationship between <code>balance</code> and <code>ethnicity</code>.</p>
<p>Using this dummy variable approach presents no difficulties when using both quantitative and qualitative predictors. For example, to regress <code>balance</code> on both a quantitative varaible such as <code>income</code> and a qualitative variable such as <code>student</code>, we must simply create a dummy varaible for <code>student</code> and then fit a multiple linear regression model using <code>income</code> and the dummy variable as the predictors for credit card balance.</p>
</section>
<section id="extensions-of-the-linear-model" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2"><span class="header-section-number">2.3.2</span> Extensions of the Linear Model</h3>
<p>Linear regression model is very interpretable and works quite well on many real-world problems. However, it makes several highly restrictive assumptions that are ofthen violated in practice. Two of them ost important assumptions state that the relationship between the predictors and response are <em>additive</em> and <em>linear</em>.</p>
<p>The <em>additive</em> assumption means that the effect of changes in a predictor <span class="math inline">\(x_j\)</span> on the response <span class="math inline">\(Y\)</span> is independent of the vlaues of the other predictors.</p>
<p>The <em>linear</em> assumption means thatt the change in the response <span class="math inline">\(Y\)</span> due to one-unit change in <span class="math inline">\(x_j\)</span> is constant, regardless of the vlaue of <span class="math inline">\(x_j\)</span>.</p>
<p>We can relax these assumptions. Here some classical approaches to do that</p>
<p><strong>Removing the Additive Assumption</strong></p>
<p>From <code>Advertising</code> data, we concluded that both <code>TV</code> and <code>radio</code> seem to be associated with <code>sales</code>. Our model was linear; the effect of <code>TV</code> and <code>radio</code> advertising spending on sales is independent of each other, and their effect is constant no matter the level of spending.</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 TV_i + \beta_2 radio_i + \epsilon_i
\]</span> this model means that, the average effect on sales of a one unit increase in tv is always <span class="math inline">\(\beta_1\)</span> regardless of the amount spent on radio.</p>
<p>However, this simple model may be incorrect. Suppose that spending money on radio advertising actually increases the effectiveness of TV advertising, so that the slope term for <code>TV</code> should increase as <code>radio</code> increases. In this situation, given a fixed budget $100,000, spending half on <code>radio</code> and half on <code>TV</code> may increase <code>sales</code> more than allocating the entire amount to either <code>TV</code> or to <code>radio</code>. In marketing this is known as the <em>synergy effect</em>, in statistics <em>interaction effect</em>.</p>
<p>Consider the standard linear regression with two variables,</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \epsilon
\]</span> Here if we increaes <span class="math inline">\(x_1\)</span> by one unit, <span class="math inline">\(Y\)</span> will increase by an average of <span class="math inline">\(\beta_1\)</span> units. The presence of <span class="math inline">\(x_2\)</span> does not alter this statement-regardless of the value of <span class="math inline">\(x_2\)</span>, a one-unit increase in <span class="math inline">\(x_1\)</span> will lead to <span class="math inline">\(\beta_1\)</span> unit increae in <span class="math inline">\(Y\)</span>.</p>
<p>We can extend this model by allowing interaction effects by including a third predictor, called an <em>interaction term</em>, which is constructed by computing the product of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>:</p>
<p><span class="math display">\[
Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \epsilon
\]</span> (3.31)</p>
<p>We can write this equation</p>
<p><span class="math display">\[
\begin{align}
Y &amp;= \beta_0 + (\beta_1 + \beta_3 x_2)x_1 + \beta_2x_2 +\epsilon \\
&amp;= \beta_0 + \tilde{\beta_1}x_1 + \beta_2x_2 + \epsilon
\end{align}
\]</span> where <span class="math inline">\(\tilde{\beta_1} = \beta_1 + \beta_3x_2\)</span>. Since <span class="math inline">\(\tilde{\beta_1}\)</span> changes with <span class="math inline">\(x_2\)</span>, the effect of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(Y\)</span> is no longer constant: adjusting <span class="math inline">\(x_2\)</span> will change the impact of <span class="math inline">\(x_1\)</span> on <span class="math inline">\(Y\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class='callout-icon'></i>
</div>
<div class="callout-title-container flex-fill">
Productivy of a factory
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose that we are interested in studying the productivity of a factory. We want to predict the number of <code>units</code> produced on the basis of the number of production <code>lines</code> and the total number of <code>workers</code>. Probably the effect of increasing <code>lines</code> on <code>units</code> produced will depend on the number of <code>workers</code>, since if no workers are available to operate the lines, then increasing the number of lines will not increase the production. This suggest to include an interaction term between <code>lines</code> and <code>workers</code> in a linear model to predict <code>units</code>.</p>
<p>Suppose when we fit the model, we obtain</p>
<p><span class="math display">\[
\begin{align}
units &amp;\approx 1.2 + 3.4 \times lines + 0.22 \times workers + 1.4 \times (lines \times workers) \\
&amp;= 1.2 + (3.4 + 1.4 \times workers) \times lines + 0.22 \times workers
\end{align}
\]</span> Adding an addtional line will increase the number of units produced by <span class="math inline">\(3.4 + 1.4 \times workers\)</span>. Hence, the more <code>workers</code> we have, the stronger will be the effect of <code>lines</code>.</p>
</div>
</div>
<p>For the advitising, a linear model that uses <code>radio</code>, <code>TV</code> and interaction between the two to predict <code>sales</code> takes the form</p>
<p><span class="math display">\[
\begin{align}
sales &amp;= \beta_0 + \beta_1 \times TV + \beta_2 \times radio + \beta_3 \times(radio \times TV) + \epsilon \\
&amp;= \beta_0 + (\beta_1 + \beta_3 \times radio)\times Tv + \beta_2 \times radio + \epsilon
\end{align}
\]</span> (3.33) We can interpret <span class="math inline">\(\beta_3\)</span> as the increase in the effectiveness of TV advertising for a one unit increse in radio advertising (or vice versa). The coefficients that result from fitting the model (3.33) are</p>
<div class="cell">
<div class="sourceCode" id="cb146"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb146-4"><a href="#cb146-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> TV<span class="sc">*</span>radio, advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb146-5"><a href="#cb146-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb146-6"><a href="#cb146-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = sales ~ TV + radio + TV * radio, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.3366 -0.4028  0.1831  0.5948  1.5246 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***
TV          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***
radio       2.886e-02  8.905e-03   3.241   0.0014 ** 
TV:radio    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9435 on 196 degrees of freedom
Multiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 
F-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Adding the interaction term increased the <span class="math inline">\(R^2\)</span> significantly from 0.8972 to 0.9678, RSE from 1.681 to 0.9435.</p>
<p>The p-value for the interaction term is very low; <span class="math inline">\(H_\alpha : \beta_3 \neq 0\)</span>. This means that the relationship is not additive.</p>
<p>To interpret the coefficients:</p>
<p>$1,000 increse in <code>TV</code> advertising results with <span class="math inline">\(\hat{\beta_1} +\hat{\beta_3}\times radio = \$19.1 + \$1.09 \times radio\)</span> increase in sales on average.</p>
<p>$1,000 invrease in <code>radio</code> advertising results with <span class="math inline">\(\hat{\beta_2} + \hat{\beta_3} \times TV = \$28.9 + \$1.09 \times TV\)</span> increase in sales on average.</p>
<p>All p-values are significant =&gt; all three varibles should be included in the model.</p>
<p>Sometimes interaction term has a very small pvalue but the associated main effects(in this case <code>TV</code> and <code>radio</code>) do not. The <em>hieararchial principle states that if we include an interaction in a model, we should also include the main effects, even if the p-values associated with their coefficients are not significant.</em></p>
<p>Here both our varaibles were quantitative. However, the consept of interaction applies to qualitative varaibles, or combination of qualitative and quantitative varibles. Actually interaction between a quantitative and qualitative variable has a particularly nice interpreateion:</p>
<p>Consider the <code>Credit</code> data set. Suppose we want to predict <code>balance</code> using <code>income</code>(quantitative) and <code>student</code>(qualitative) varaibles. In the absence of an interaction term the model takes the form</p>
<p><span class="math display">\[
balance_i  \approx \beta_0 + \beta_1 \times income_i +
\begin{cases}
\beta_2 &amp; \text{if} \space i\text{th} \space \text{person is student} \\
0 &amp; \text{if} \space i\text{th} \space \text{person is not student}
\end{cases}
\]</span></p>
<p><span class="math display">\[
balance_i = \beta_1 \times income +
\begin{cases}
\beta_0 + \beta_2 &amp; \text{if} \space i\text{th} \space \text{person is student} \\
\beta_0 &amp;\text{if} \space i\text{th} \space \text{person is student}
\end{cases}
\]</span> (3.34)</p>
<p>Notice that this amounts to fitting two parallel lines to the data, one for students and one for non-students. The lines for students and non students have different intercepts, <span class="math inline">\(\beta_0 + \beta_2\)</span> versus <span class="math inline">\(\beta_0\)</span>, but the slope <span class="math inline">\(\beta_1\)</span> is the same.</p>
<div class="cell">
<div class="sourceCode" id="cb148"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb148-3"><a href="#cb148-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb148-4"><a href="#cb148-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Balance <span class="sc">~</span> Income <span class="sc">+</span> Student, Credit) <span class="sc">%&gt;%</span> </span>
<span id="cb148-5"><a href="#cb148-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb148-6"><a href="#cb148-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = Balance ~ Income + Student, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-762.37 -331.38  -45.04  323.60  818.28 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 211.1430    32.4572   6.505 2.34e-10 ***
Income        5.9843     0.5566  10.751  &lt; 2e-16 ***
StudentYes  382.6705    65.3108   5.859 9.78e-09 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 391.8 on 397 degrees of freedom
Multiple R-squared:  0.2775,    Adjusted R-squared:  0.2738 
F-statistic: 76.22 on 2 and 397 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Average Non student balance is $211.1430; students have $382.6705 more balance on average compared to non students. $1,000 increase in income increases balance by $5,984 on average. All coefficients are statistically significant. <span class="math inline">\(R^2 = 0.2775\)</span></p>
<div class="cell">
<div class="sourceCode" id="cb150"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> </span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">y=</span>Balance, <span class="at">x=</span>Income) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">shape =</span><span class="cn">NA</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fl">211.1430</span>, <span class="at">slope =</span> <span class="fl">5.9843</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size=</span><span class="fl">1.2</span>) <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="fl">593.8135</span>, <span class="at">slope =</span> <span class="fl">5.9843</span>, <span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>, <span class="at">size=</span> <span class="fl">1.2</span>) <span class="sc">+</span> <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">150</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">200</span>,<span class="dv">1400</span>)) <span class="sc">+</span> <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1400</span>,<span class="dv">400</span>)) <span class="sc">+</span> <span class="fu">theme_clean</span>() <span class="sc">+</span> <span class="fu">geom_text</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">80</span>,<span class="dv">80</span>), <span class="at">y =</span><span class="fu">c</span>(<span class="dv">1130</span>,<span class="dv">640</span>), <span class="at">z =</span> <span class="fu">c</span>(<span class="st">&quot;Student&quot;</span>,<span class="st">&quot;non-student&quot;</span>)), <span class="at">inherit.aes =</span> F, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y, <span class="at">label=</span>z), <span class="at">angle=</span><span class="fl">25.9</span>) <span class="ot">-&gt;</span> p1</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>p1</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-83-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Notice the since the slopes are same, two lines are parallel; average effect of income on balance does not depend on whether or not the individual is a student. This is a limitation; change in income may have a very different effect on the credit card balance of a student versus non student.</p>
<p>This limitation can be addressed by adding an interaction varaible, created by multiplying <code>student</code> and <code>income</code> with the dummy for student. Our model now becomes</p>
<p><span class="math display">\[
balance_i \approx \beta_0 + \beta_1 \times income_i +
\begin{cases}
\beta_2 + \beta_3 \times income_i &amp; \text{if student} \\
0 &amp; \text{if not student}
\end{cases}
\]</span> <span class="math display">\[
balance_i =
\begin{cases}
(\beta_0 + \beta_2) + (\beta_1 + \beta_3) \times income_i &amp; \text{if student} \\
\beta_0 + \beta_1 \times income_i &amp; \text{if not student}
\end{cases}
\]</span> (3.35)</p>
<p>Again, our intercepts differ based on whether individual is student or not. However, this time slope also differs!</p>
<p>Lets estimate this model</p>
<div class="cell">
<div class="sourceCode" id="cb151"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb151-4"><a href="#cb151-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Balance <span class="sc">~</span> Income <span class="sc">+</span> Student <span class="sc">+</span> Income <span class="sc">*</span> Student, Credit) <span class="sc">%&gt;%</span> </span>
<span id="cb151-5"><a href="#cb151-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb151-6"><a href="#cb151-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = Balance ~ Income + Student + Income * Student, 
    data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-773.39 -325.70  -41.13  321.65  814.04 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       200.6232    33.6984   5.953 5.79e-09 ***
Income              6.2182     0.5921  10.502  &lt; 2e-16 ***
StudentYes        476.6758   104.3512   4.568 6.59e-06 ***
Income:StudentYes  -1.9992     1.7313  -1.155    0.249    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 391.6 on 396 degrees of freedom
Multiple R-squared:  0.2799,    Adjusted R-squared:  0.2744 
F-statistic:  51.3 on 3 and 396 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>This results in</p>
<div class="cell">
<div class="sourceCode" id="cb153"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">intercept =</span> <span class="fu">c</span>(<span class="fl">200.6232</span>, <span class="fl">200.6232+476.6758</span>),</span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> <span class="fu">c</span>(<span class="fl">6.2182</span>, <span class="fl">6.2182</span> <span class="sc">-</span> <span class="fl">1.9992</span>),</span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="fu">c</span>(<span class="st">&quot;Non-student&quot;</span>, <span class="st">&quot;student&quot;</span>)</span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 2 × 3
  intercept income type       
      &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;      
1      201.   6.22 Non-student
2      677.   4.22 student    </code></pre>
</div>
</div>
<p>and becomes</p>
<div class="cell">
<div class="sourceCode" id="cb155"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>Credit <span class="sc">%&gt;%</span> </span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x =</span> Income, <span class="at">y =</span> Balance) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">shape =</span><span class="cn">NA</span>)<span class="sc">+</span></span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">201</span>, <span class="at">slope =</span> <span class="fl">6.22</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">size =</span><span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">677</span>, <span class="at">slope =</span> <span class="fl">4.22</span>, <span class="at">size =</span> <span class="fl">1.2</span>, <span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>) <span class="sc">+</span>  <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">150</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">200</span>,<span class="dv">1400</span>)) <span class="sc">+</span> <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1400</span>,<span class="dv">400</span>)) <span class="sc">+</span> <span class="fu">theme_clean</span>() <span class="sc">+</span> <span class="fu">geom_text</span>(<span class="at">data =</span> <span class="fu">tibble</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">80</span>,<span class="dv">80</span>), <span class="at">y =</span><span class="fu">c</span>(<span class="dv">1130</span>,<span class="dv">640</span>), <span class="at">z =</span> <span class="fu">c</span>(<span class="st">&quot;Student&quot;</span>,<span class="st">&quot;non-student&quot;</span>)), <span class="at">inherit.aes =</span> F, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y, <span class="at">label=</span>z), <span class="at">angle=</span><span class="fl">25.9</span>) <span class="ot">-&gt;</span> p2</span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a>p2</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-86-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Lets merge this two plots together</p>
<div class="cell">
<div class="sourceCode" id="cb156"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1,p2, <span class="at">ncol =</span><span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-87-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Slope for studens is lower than the slope for non-students =&gt; increases in income are associated with smaller increases in credit card balance among students as copared to non-students.</p>
<p><strong>Not-linear Relationships</strong></p>
<p>Linear model assumes linear relationship between the response and the predictors. However, this is often not true. We can relax this assumption using <em>polynomial regression</em>.</p>
<p>Consider <code>Auto</code></p>
<div class="cell">
<div class="sourceCode" id="cb157"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>Auto <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>horsepower, <span class="at">y =</span> mpg) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">shape =</span><span class="dv">1</span>, <span class="at">size =</span><span class="fl">1.4</span>) <span class="sc">+</span> </span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F, <span class="at">color =</span><span class="st">&quot;#FEBF63&quot;</span>) <span class="sc">+</span></span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x,<span class="dv">2</span>), <span class="at">color =</span><span class="st">&quot;#7FDBDA&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">formula =</span> y <span class="sc">~</span> <span class="fu">poly</span>(x,<span class="dv">5</span>), <span class="at">color =</span><span class="st">&quot;#ADE498&quot;</span>, <span class="at">se=</span>F) <span class="sc">+</span> <span class="fu">theme_blank</span>() </span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="Chapter3_files/figure-html/unnamed-chunk-88-1.png" class="img-fluid" width="672" /></p>
<figcaption>linear regresion fit is in orange, blue curve is a linear regression fit for a model that includes horsepower^2, and green curve includes up to horsepower^5</figcaption>
</figure>
</div>
</div>
</div>
<p>It is obvious that there is relationship between <code>mpg</code> and <code>horsepower</code>. But it seems like this relationship is not linear: the data suggest a curved relationship.</p>
<p>A simple approach for incorporating non linear associations in a linear model is to include transformed versions of the predictors in the model. For example figure above seem to have a <em>quadratic</em> shape, suggesting that a model of the form</p>
<p><span class="math display">\[
mpg = \beta_0 + \beta_1 \times horsepower + \beta_2 \times horsepower^2 + \epsilon
\]</span> May be a better fit. Equation</p>
<p>You can do it in different ways: 1.</p>
<div class="cell">
<div class="sourceCode" id="cb159"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>Auto <span class="sc">%&gt;%</span> </span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">hp.sq =</span> horsepower<span class="sc">^</span><span class="dv">2</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb159-3"><a href="#cb159-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lm</span>(mpg<span class="sc">~</span>horsepower <span class="sc">+</span> hp.sq,.) <span class="sc">%&gt;%</span> </span>
<span id="cb159-4"><a href="#cb159-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ horsepower + hp.sq, data = .)

Residuals:
     Min       1Q   Median       3Q      Max 
-14.7135  -2.5943  -0.0859   2.2868  15.8961 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 56.9000997  1.8004268   31.60   &lt;2e-16 ***
horsepower  -0.4661896  0.0311246  -14.98   &lt;2e-16 ***
hp.sq        0.0012305  0.0001221   10.08   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.374 on 389 degrees of freedom
Multiple R-squared:  0.6876,    Adjusted R-squared:  0.686 
F-statistic:   428 on 2 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<ol start="2" type="1">
<li></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb161"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower <span class="sc">+</span> <span class="fu">I</span>(horsepower<span class="sc">^</span><span class="dv">2</span>), Auto))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ horsepower + I(horsepower^2), data = Auto)

Residuals:
     Min       1Q   Median       3Q      Max 
-14.7135  -2.5943  -0.0859   2.2868  15.8961 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     56.9000997  1.8004268   31.60   &lt;2e-16 ***
horsepower      -0.4661896  0.0311246  -14.98   &lt;2e-16 ***
I(horsepower^2)  0.0012305  0.0001221   10.08   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.374 on 389 degrees of freedom
Multiple R-squared:  0.6876,    Adjusted R-squared:  0.686 
F-statistic:   428 on 2 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<ol start="3" type="1">
<li></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb163"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> <span class="fu">poly</span>(horsepower,<span class="dv">2</span>, <span class="at">raw=</span>T), Auto))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ poly(horsepower, 2, raw = T), data = Auto)

Residuals:
     Min       1Q   Median       3Q      Max 
-14.7135  -2.5943  -0.0859   2.2868  15.8961 

Coefficients:
                                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                   56.9000997  1.8004268   31.60   &lt;2e-16 ***
poly(horsepower, 2, raw = T)1 -0.4661896  0.0311246  -14.98   &lt;2e-16 ***
poly(horsepower, 2, raw = T)2  0.0012305  0.0001221   10.08   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.374 on 389 degrees of freedom
Multiple R-squared:  0.6876,    Adjusted R-squared:  0.686 
F-statistic:   428 on 2 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<ol start="4" type="1">
<li></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb165"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">nls</span>(mpg <span class="sc">~</span>a <span class="sc">+</span> b <span class="sc">*</span> horsepower <span class="sc">+</span> c <span class="sc">*</span> horsepower<span class="sc">^</span><span class="dv">2</span>, <span class="at">data =</span> Auto, <span class="at">start =</span> <span class="fu">c</span>(<span class="at">a=</span><span class="dv">0</span>,<span class="at">b=</span><span class="dv">0</span>,<span class="at">c=</span><span class="dv">0</span>)))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Formula: mpg ~ a + b * horsepower + c * horsepower^2

Parameters:
    Estimate Std. Error t value Pr(&gt;|t|)    
a 56.9000997  1.8004268   31.60   &lt;2e-16 ***
b -0.4661896  0.0311246  -14.98   &lt;2e-16 ***
c  0.0012305  0.0001221   10.08   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.374 on 389 degrees of freedom

Number of iterations to convergence: 1 
Achieved convergence tolerance: 1.293e-09</code></pre>
</div>
</div>
<p>–</p>
<div class="cell">
<div class="sourceCode" id="cb167"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower, Auto))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ horsepower, data = Auto)

Residuals:
     Min       1Q   Median       3Q      Max 
-13.5710  -3.2592  -0.3435   2.7630  16.9240 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 39.935861   0.717499   55.66   &lt;2e-16 ***
horsepower  -0.157845   0.006446  -24.49   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.906 on 390 degrees of freedom
Multiple R-squared:  0.6059,    Adjusted R-squared:  0.6049 
F-statistic: 599.7 on 1 and 390 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb169"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(mpg <span class="sc">~</span> horsepower <span class="sc">+</span> <span class="fu">I</span>(horsepower<span class="sc">^</span><span class="dv">2</span>),Auto))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ horsepower + I(horsepower^2), data = Auto)

Residuals:
     Min       1Q   Median       3Q      Max 
-14.7135  -2.5943  -0.0859   2.2868  15.8961 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     56.9000997  1.8004268   31.60   &lt;2e-16 ***
horsepower      -0.4661896  0.0311246  -14.98   &lt;2e-16 ***
I(horsepower^2)  0.0012305  0.0001221   10.08   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 4.374 on 389 degrees of freedom
Multiple R-squared:  0.6876,    Adjusted R-squared:  0.686 
F-statistic:   428 on 2 and 389 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The <span class="math inline">\(R^2\)</span> of the quadratic fit is 0.688, compared to 0.606 for the linear fit. And the p-value is highly significant for quadratic model.</p>
<p>If adding <span class="math inline">\(horsepower^2\)</span> increses the <span class="math inline">\(R^2\)</span> why not include <span class="math inline">\(^3\)</span> or <span class="math inline">\(^4\)</span> or more?</p>
<p>Lets estimate the green curve on the previous plot</p>
<div class="cell">
<div class="sourceCode" id="cb171"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(horsepower <span class="sc">~</span> <span class="fu">poly</span>(horsepower,<span class="dv">5</span>, <span class="at">raw=</span>T),Auto))</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in summary.lm(lm(horsepower ~ poly(horsepower, 5, raw = T), Auto)):
essentially perfect fit: summary may be unreliable</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = horsepower ~ poly(horsepower, 5, raw = T), data = Auto)

Residuals:
       Min         1Q     Median         3Q        Max 
-7.256e-13 -1.620e-15 -1.000e-16  3.540e-15  3.819e-14 

Coefficients:
                                Estimate Std. Error    t value Pr(&gt;|t|)    
(Intercept)                    2.739e-13  2.468e-13  1.110e+00    0.268    
poly(horsepower, 5, raw = T)1  1.000e+00  1.125e-14  8.887e+13   &lt;2e-16 ***
poly(horsepower, 5, raw = T)2  1.496e-16  1.946e-16  7.690e-01    0.442    
poly(horsepower, 5, raw = T)3 -1.196e-18  1.598e-18 -7.480e-01    0.455    
poly(horsepower, 5, raw = T)4  4.368e-21  6.255e-21  6.980e-01    0.485    
poly(horsepower, 5, raw = T)5 -5.894e-24  9.373e-24 -6.290e-01    0.530    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.736e-14 on 386 degrees of freedom
Multiple R-squared:      1, Adjusted R-squared:      1 
F-statistic: 8.299e+31 on 5 and 386 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The green fit seems unnecassasrliy wiggly- that is it is unclear includig the additional terms really has led to a better fit to the data.</p>
<p>The approach we have just described for extending the linear model to accomodate non-linear relationships is known as <em>polynomial regression</em>, since we have included polynomial functions of the predictors in the regression model. Check out Chapter 7.</p>
</section>
<section id="potential-problems" class="level3" data-number="2.3.3">
<h3 data-number="2.3.3"><span class="header-section-number">2.3.3</span> Potential Problems</h3>
<p>When we fit a linear regression model to a particular data set, many problems may occur. Most common among these are the following</p>
<ol type="1">
<li><p><em>Non-linearity of the response-predictor relationships</em>.</p></li>
<li><p><em>Correalation of error terms</em></p></li>
<li><p><em>Non-constant variance of error terms</em></p></li>
<li><p><em>Outliers</em></p></li>
<li><p><em>High-leverage points</em></p></li>
<li><p><em>Collinearity</em></p></li>
</ol>
<p>Lets breifly discuss each</p>
<p><strong>1.Non-linearity of the Data</strong></p>
<p>Linear regression assumes there is a straight line relationship between the predictors and the respose. If the true relationship is far from linear, then our estimations are not good. Also our prediction accuracy is reduced.</p>
<p><em>Residual plots</em> are a useful graphical tool for identifying non-linearity.</p>
<p>We can plot the residuals <span class="math inline">\(e_i = y_i - \hat{y_i}\)</span> versus <span class="math inline">\(x_i\)</span> for Simple linear regression.</p>
<p>For multiple linear regression since we have lost of <span class="math inline">\(x_i\)</span> we plot residuals versus predicted values(<span class="math inline">\(e_i\)</span> vs <span class="math inline">\(\hat{y_i}\)</span>).</p>
<p>We want to have <em>no visible pattern</em>. If there is a pattern =&gt; problem!</p>
<p>So what do we expect a plot of “fitted” vs “resid”; if the relationship is linear as the “fitted” values increase “resid” should not increase or decrease, should swing with no relationship: linear.</p>
<p>If the relationship is not linear then we expect ot see a pattern because as the fitted values increase the resiudls will increase.</p>
<div class="cell">
<div class="sourceCode" id="cb174"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb174-2"><a href="#cb174-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb174-3"><a href="#cb174-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb174-4"><a href="#cb174-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(mpg <span class="sc">~</span> horsepower, Auto) <span class="sc">%&gt;%</span> </span>
<span id="cb174-5"><a href="#cb174-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb174-6"><a href="#cb174-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>() </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 392 × 9
   .rownames   mpg horsepower .fitted .resid    .hat .sigma   .cooksd .std.resid
   &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;
 1 1            18        130   19.4  -1.42  0.00368   4.91   1.54e-4    -0.289 
 2 2            15        165   13.9   1.11  0.00888   4.91   2.31e-4     0.227 
 3 3            18        150   16.3   1.74  0.00613   4.91   3.91e-4     0.356 
 4 4            16        150   16.3  -0.259 0.00613   4.91   8.66e-6    -0.0530
 5 5            17        140   17.8  -0.838 0.00473   4.91   6.96e-5    -0.171 
 6 6            15        198    8.68  6.32  0.0177    4.90   1.52e-2     1.30  
 7 7            14        220    5.21  8.79  0.0256    4.89   4.33e-2     1.82  
 8 8            14        215    6.00  8.00  0.0236    4.89   3.30e-2     1.65  
 9 9            14        225    4.42  9.58  0.0276    4.89   5.57e-2     1.98  
10 10           15        190    9.95  5.05  0.0152    4.91   8.31e-3     1.04  
# ℹ 382 more rows</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb176"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb176-2"><a href="#cb176-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb176-3"><a href="#cb176-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb176-4"><a href="#cb176-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(mpg <span class="sc">~</span> horsepower, Auto) <span class="sc">%&gt;%</span> </span>
<span id="cb176-5"><a href="#cb176-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb176-6"><a href="#cb176-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb176-7"><a href="#cb176-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>horsepower, <span class="at">y =</span> .resid) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">se=</span>F) <span class="sc">+</span> <span class="fu">theme_light</span>()</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39;</code></pre>
</div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-97-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Here we observe a U-shape trend; indicating non-linear relationship between <code>horsepower</code> and <code>mpg</code>.</p>
<p>Lets do a plot of fitted vs residual for linear and non linear regression:</p>
<div class="cell">
<div class="sourceCode" id="cb178"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb178-1"><a href="#cb178-1" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(</span>
<span id="cb178-2"><a href="#cb178-2" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb178-3"><a href="#cb178-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb178-4"><a href="#cb178-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb178-5"><a href="#cb178-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(mpg <span class="sc">~</span> horsepower, Auto) <span class="sc">%&gt;%</span> </span>
<span id="cb178-6"><a href="#cb178-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb178-7"><a href="#cb178-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb178-8"><a href="#cb178-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">se=</span>F) <span class="sc">+</span> <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span> <span class="fu">theme_light</span>()</span>
<span id="cb178-9"><a href="#cb178-9" aria-hidden="true" tabindex="-1"></a>,</span>
<span id="cb178-10"><a href="#cb178-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb178-11"><a href="#cb178-11" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb178-12"><a href="#cb178-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb178-13"><a href="#cb178-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb178-14"><a href="#cb178-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(mpg <span class="sc">~</span> horsepower <span class="sc">+</span> <span class="fu">I</span>(horsepower<span class="sc">^</span><span class="dv">2</span>), Auto) <span class="sc">%&gt;%</span> </span>
<span id="cb178-15"><a href="#cb178-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb178-16"><a href="#cb178-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb178-17"><a href="#cb178-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y=</span>.resid) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">se=</span>F) <span class="sc">+</span> <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span> <span class="fu">theme_light</span>(), <span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39;
`geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39;</code></pre>
</div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-98-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Here is the plots. On the left fitted vs resid for regressing horsepower onto mpg, on the right regressing horsepower and horsepower^2 onto mpg.</p>
<p>Blue line is a smooth fit to the residuals to identify trends easily. The residuals on the left panel exhibit a clear U shape, which is a strong indication that the true relationship is not linear.</p>
<p>Right hand panel displays a little pattern, suggesting that the quadratic term improves the fit to the data.</p>
<p>If the residual plot indicates that there are non-linear associations in the data, then a simple approach is to use non-linear transformations of the predictors, such as <span class="math inline">\(\log X\)</span>, <span class="math inline">\(\sqrt{X}\)</span>, and <span class="math inline">\(X^2\)</span>, in the regression model. We will discuss more later on.</p>
<p><strong>2.Correlation of Error Terms</strong></p>
<p>An important assumption of the linear regression is that error terms <span class="math inline">\(\epsilon_1, \epsilon_2, \dots, \epsilon_n\)</span> are uncorrelated. This means that <span class="math inline">\(\epsilon_{i+1} \neq f(\epsilon_i)\)</span>. The standard errors that are computed for the estimated regression coeffieints or the fitted values are based on this assumption. If there is correaltion among the error terms, the estimated standard errors will tend to underestimate the true standard errors =&gt; confidence and prediction intervals will be narrower than they should be. P-values will be lower as well, causing false discoveries perhaps.</p>
<p>Usually correlation among error terms occur in <em>time series</em> data. In many cases, observations that are obtained at adjacent time points will have positevely correalated errors. To test this we can plot the residuals from our model as a function of time. If the errors are uncorrelated, then we expect no pattern. If the error terms are positevly correlated, then we may see <em>tracking</em> in the residuals–<em>adjacent residuals may have similar values</em>.</p>
<p><img src="fig3.10.png" class="img-fluid" /> Check out Figure 3.10. In the top panel, we see the residuals from a linear regression fit to data generated with uncorrelated errors. Adjacent years don’t take similar values; there is no evidence of a time-related trend in the residuals. But in the bottom panel, we see plotted residuals which have correlation 0.9 with time: now there is a clear pattern in the residuals–adjacent residuals tend to take on similar values. Finally, the center panel illustrates a more moderate case in which residuals had a correlation of 0.5. There is still evidence of tracking, but the pattern is less clear.</p>
<p>Correlation among the error terms can also occur outside of time series data. For instance, consider a study where we predict people’s hights from their weights. The assumption of uncorrelated errors could be violated if some of the individauls in the study are members of the same family, or eat the same diet, or have been exposed to same environmental factors.</p>
<p><strong>3.Non-constant Variance of Error Terms</strong></p>
<p>Another important assumption of the linear regression model is that error terms have a constant variance, <span class="math inline">\(\text{Var}(\epsilon_i) = \sigma^2\)</span>. The standard errors, confidence intervals, and hypothesis tests rely upon this assumption.</p>
<p>Unfortunately, often variances of the error terms are non-constant =&gt; <em>heteroscedasticity</em>. For instance, variances of the error terms may increase with the value of the response. We can identify non-constant variances in the errors from the presence of a <em>funnel shape</em> in the residual plot.</p>
<p><img src="fig3.11.png" class="img-fluid" /> On the left panel magnitude of the residuals tends to increase with the fitted values. When faced with this problem, one possible solution is to transform the response <span class="math inline">\(Y\)</span> using a concave function such as <span class="math inline">\(\log Y\)</span> or <span class="math inline">\(\sqrt{Y}\)</span>. Such a transformation results in a greater amount of shrinkage of the larger responses, leading to a reduction in heteroscedasticity. On the right hand panel we see that residuals apper to have constant variance.</p>
<p><strong>4.Outliers</strong></p>
<p>An <em>outlier</em> is a point for which <span class="math inline">\(y_i\)</span> is far from the vlaue predicted by the model.</p>
<p><img src="fig3.12.png" class="img-fluid" /></p>
<p>The red point (observation 20) in the left-hand panel of Figure 3.12 illustrates a typical outlier. The red solid line is the least squares regression fit, while the blue dashed line is the least squares fit after removel of the outlier. In this case, removing the outlier has little effect on the least squares line: it leads to almost no change in the slope, and a minuscule reduction in the intercept. This is normal. However, it can cause other problems: RSE is 1.09 when outlier is included, but it is only 0.77 when excluded =&gt; RSE is used to calculate all confidence intervals, p values =&gt; bias. <span class="math inline">\(R^2\)</span> also decreases from 0.829 to 0.805 when included outlier.</p>
<p>Residual plots can be used to identify outliers =&gt; center panel of Figure 3.12. But it can be difficult to decide how large a residual needs to before we consider the point to be an outlier. To address this problem instead of plotting the residuals we can plot the <em>studentized residuals</em> computed by dividing each residuls <span class="math inline">\(e_i\)</span> by its estimated standard error.</p>
<p><span class="math display">\[
e_i^*=\frac{e_i}{sd(e_i)} = \frac{e_i}{\sqrt{MSE(1-h_{ii})}}
\]</span> <span class="math inline">\(h_{ii}\)</span> is leverage point.</p>
<p>Observations whose studentized residuals are greater than 3 in absolute value are possible outliers. In the right-hand panel of Figure 3.12 the outlier’s studentized residual exceeds 6; while all other observations have studentized residauls between -2 and 2.</p>
<div class="cell">
<div class="sourceCode" id="cb180"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb180-1"><a href="#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb180-2"><a href="#cb180-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb180-3"><a href="#cb180-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb180-4"><a href="#cb180-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio,advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb180-5"><a href="#cb180-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb180-6"><a href="#cb180-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb180-7"><a href="#cb180-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">.std.resid_3 =</span> <span class="fu">ifelse</span>(<span class="fu">abs</span>(.std.resid) <span class="sc">&gt;=</span><span class="dv">3</span>,T,F), <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb180-8"><a href="#cb180-8" aria-hidden="true" tabindex="-1"></a>  print <span class="sc">%&gt;%</span> </span>
<span id="cb180-9"><a href="#cb180-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>.fitted, <span class="at">y =</span>.std.resid, <span class="at">color =</span> .std.resid_3) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb180-10"><a href="#cb180-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span></span>
<span id="cb180-11"><a href="#cb180-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">ifelse</span>(.std.resid_3 <span class="sc">==</span> T,id,<span class="st">&quot;&quot;</span>)), <span class="at">nudge_x =</span> <span class="fl">0.5</span>, <span class="at">show.legend =</span> F)<span class="sc">+</span> <span class="fu">theme_light</span>() </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 200 × 11
   sales    TV radio .fitted  .resid    .hat .sigma   .cooksd .std.resid
   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;
 1  22.1 230.   37.8   20.6   1.54   0.0140    1.68 0.00406       0.925 
 2  10.4  44.5  39.3   12.3  -1.95   0.0188    1.68 0.00871      -1.17  
 3   9.3  17.2  45.9   12.3  -3.04   0.0295    1.67 0.0341       -1.83  
 4  18.5 152.   41.3   17.6   0.883  0.0124    1.68 0.00117       0.528 
 5  12.9 181.   10.8   13.2  -0.324  0.00951   1.69 0.000120     -0.194 
 6   7.2   8.7  48.9   12.5  -5.31   0.0347    1.64 0.124        -3.22  
 7  11.8  57.5  32.8   11.7   0.0818 0.0129    1.69 0.0000105     0.0490
 8  13.2 120.   19.6   12.1   1.09   0.00576   1.68 0.000823      0.653 
 9   4.8   8.6   2.1    3.71  1.09   0.0271    1.68 0.00401       0.658 
10  10.6 200.    2.6   12.6  -1.95   0.0171    1.68 0.00797      -1.17  
# ℹ 190 more rows
# ℹ 2 more variables: .std.resid_3 &lt;lgl&gt;, id &lt;int&gt;</code></pre>
</div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-99-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>or</p>
<div class="cell">
<div class="sourceCode" id="cb182"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio,advertising), <span class="at">which =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-100-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>We have spotted that 6th and 131 are possible outliers.</p>
<p>Here is all the data regression result:</p>
<div class="cell">
<div class="sourceCode" id="cb183"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb183-4"><a href="#cb183-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb183-5"><a href="#cb183-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb183-6"><a href="#cb183-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = sales ~ TV + radio, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb185"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb185-3"><a href="#cb185-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb185-4"><a href="#cb185-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb185-5"><a href="#cb185-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb185-6"><a href="#cb185-6" aria-hidden="true" tabindex="-1"></a>  car<span class="sc">::</span><span class="fu">outlierTest</span>()<span class="ot">-&gt;</span> outs</span>
<span id="cb185-7"><a href="#cb185-7" aria-hidden="true" tabindex="-1"></a>outs <span class="co"># 131th value is outlier</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     rstudent unadjusted p-value Bonferroni p
131 -5.714235         4.0499e-08   8.0998e-06</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb187"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb187-3"><a href="#cb187-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb187-4"><a href="#cb187-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb187-5"><a href="#cb187-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb187-6"><a href="#cb187-6" aria-hidden="true" tabindex="-1"></a>  car<span class="sc">::</span><span class="fu">outlierTest</span>(., <span class="at">cutoff =</span> <span class="fl">0.30</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     rstudent unadjusted p-value Bonferroni p
131 -5.714235         4.0499e-08   8.0998e-06
6   -3.295069         1.1678e-03   2.3356e-01</code></pre>
</div>
</div>
<p>Here is regression result after removing outliers</p>
<div class="cell">
<div class="sourceCode" id="cb189"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb189-3"><a href="#cb189-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb189-4"><a href="#cb189-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">6</span>,<span class="dv">131</span>),]) <span class="sc">%&gt;%</span> </span>
<span id="cb189-5"><a href="#cb189-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb189-6"><a href="#cb189-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = sales ~ TV + radio, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.3938 -0.8195  0.2003  1.0785  2.8134 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 3.051908   0.265279   11.51   &lt;2e-16 ***
TV          0.044220   0.001269   34.84   &lt;2e-16 ***
radio       0.195295   0.007315   26.70   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.511 on 195 degrees of freedom
Multiple R-squared:  0.9146,    Adjusted R-squared:  0.9138 
F-statistic:  1045 on 2 and 195 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><span class="math inline">\(R^2\)</span> has increased, residual standard errors has decreased, standard errors of estimates decreased and coefficients has changed.</p>
<p><strong>5.High Leverage Points</strong></p>
<p>Outliers are observations for which the response <span class="math inline">\(y_i\)</span> is unusual given the predictor <span class="math inline">\(x_i\)</span>. In contrast, observations with <em>high leverage</em> have an unusual value for <span class="math inline">\(x_i\)</span>.</p>
<p><img src="fig3.13.png" class="img-fluid" /></p>
<p>For example observation 41 in the left-hand panel of Figure 3.13 has high leverage =&gt; predictor value for this observation is large relative to other observations. The red solid line is the least squares fit to the data, the blue dashed line is the fit when obs 41 is removed.</p>
<p>Removing the high leverage observation has a much more substantial impact on the least squares line than removing an outlier. High leverage obss have a big impact on the estiamted regression line. It is important to identify them.</p>
<p>For SLR =&gt; look at the range of <span class="math inline">\(x_i\)</span> and spot the out of range observations.</p>
<p>MLR =&gt; it is possible to have an observation that is well within the range of each individual predictor’s values, but that is unusual in terms of the full set of predictors.</p>
<p>Have a look at the center panel in Figure 3.13. Most of the observations’ predictor values fall within the blue dashed ellipse, but the red observation is well outside of this range. But neither its value for <span class="math inline">\(x_1\)</span> nor <span class="math inline">\(x_2\)</span> is unusual.</p>
<p>We can quantify an observation’s leverage using the <em>leverage statistic</em>. A large value indicates a high leverage.</p>
<p>For SLR:</p>
<p><span class="math display">\[
\begin{align}
h_i &amp;= \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum_{i&#39;=1}^n(x_{i&#39;} - \bar{x})^2} \\
&amp;1/n \leq h_i \leq 1 \\
&amp;\bar{h_i} = (p+1)/n
\end{align}
\]</span> as <span class="math inline">\(x_i\)</span> increases its distance from <span class="math inline">\(\bar{x}\)</span> <span class="math inline">\(h_i\)</span> increases.</p>
<p><span class="math inline">\(h_i\)</span> is always between <span class="math inline">\(1/n\)</span> and <span class="math inline">\(1\)</span>, and the average leverage for all the observations is always equal to <span class="math inline">\((p+1)/n\)</span>. If an observation has a <span class="math inline">\(h\)</span> that greatly exceeds <span class="math inline">\((p+1)/n\)</span> then we may suspect of high leverage.</p>
<p>Right hand panel of Figure 3.13 shows studentized residuals versus <span class="math inline">\(h_i\)</span>. Obs 41 stands out as having a very high leverage statistic as well as a high studentized residual =&gt; It is an outlier as well as a high leverage observaiton. This is very dangerous. This plot also shows the reason that obs 20 had relatively little effect on the least sqaures fit in Figure 3.12: it has low leverage.</p>
<div class="cell">
<div class="sourceCode" id="cb191"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb191-3"><a href="#cb191-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb191-4"><a href="#cb191-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio, advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb191-5"><a href="#cb191-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb191-6"><a href="#cb191-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 200 × 9
   sales    TV radio .fitted  .resid    .hat .sigma   .cooksd .std.resid
   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;
 1  22.1 230.   37.8   20.6   1.54   0.0140    1.68 0.00406       0.925 
 2  10.4  44.5  39.3   12.3  -1.95   0.0188    1.68 0.00871      -1.17  
 3   9.3  17.2  45.9   12.3  -3.04   0.0295    1.67 0.0341       -1.83  
 4  18.5 152.   41.3   17.6   0.883  0.0124    1.68 0.00117       0.528 
 5  12.9 181.   10.8   13.2  -0.324  0.00951   1.69 0.000120     -0.194 
 6   7.2   8.7  48.9   12.5  -5.31   0.0347    1.64 0.124        -3.22  
 7  11.8  57.5  32.8   11.7   0.0818 0.0129    1.69 0.0000105     0.0490
 8  13.2 120.   19.6   12.1   1.09   0.00576   1.68 0.000823      0.653 
 9   4.8   8.6   2.1    3.71  1.09   0.0271    1.68 0.00401       0.658 
10  10.6 200.    2.6   12.6  -1.95   0.0171    1.68 0.00797      -1.17  
# ℹ 190 more rows</code></pre>
</div>
</div>
<p>leverages are shown in <code>.hat</code> here.</p>
<div class="cell">
<div class="sourceCode" id="cb193"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">lm</span>(sales<span class="sc">~</span>TV,advertising), <span class="at">which =</span> <span class="dv">5</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-106-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p><strong>6.Collinearity</strong></p>
<p><em>Collinearity</em> refers to the situation in which two or more predictor variables are closely related to one another.</p>
<div class="cell">
<div class="sourceCode" id="cb194"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(</span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a>  Credit <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>Limit, <span class="at">y =</span> Age) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">color =</span><span class="st">&quot;red&quot;</span>, <span class="at">alpha =</span><span class="fl">0.4</span>),</span>
<span id="cb194-3"><a href="#cb194-3" aria-hidden="true" tabindex="-1"></a>  Credit <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x=</span>Limit, <span class="at">y=</span> Rating) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">color =</span><span class="st">&quot;red&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.4</span>),</span>
<span id="cb194-4"><a href="#cb194-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ncol=</span><span class="dv">2</span></span>
<span id="cb194-5"><a href="#cb194-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img src="Chapter3_files/figure-html/unnamed-chunk-107-1.png" class="img-fluid" width="672" /></p>
<figcaption>Figure 3.14</figcaption>
</figure>
</div>
</div>
</div>
<p>In the left panel of Figure 3.14 we see no relationship, but on the right hand panel predicors are highly correlated: they are <em>collinear</em> =&gt; it is difficult to seperate out the individual effects of colliniar varaibles on the response.</p>
<p>Collinearity reduces the accuracy of the estiamtes of the regression coefficients, it causes the standard error for <span class="math inline">\(\hat{\beta_j}\)</span> to grow. t-statistic for each predictor is calculated by dividing <span class="math inline">\(\hat{\beta_j}\)</span> by its standard error =&gt; collinearity declines the t-statistics =&gt; we may fail to reject <span class="math inline">\(H_0:\beta_j = 0\)</span>.</p>
<p>Lets do two regressions:</p>
<ul>
<li>model1: balance regressed onto age and limit which has no collinearity</li>
<li>model2: balance regressed onto rating and limit which are collinear.</li>
</ul>
<div class="cell">
<div class="sourceCode" id="cb195"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb195-3"><a href="#cb195-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb195-4"><a href="#cb195-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Balance <span class="sc">~</span> Age <span class="sc">+</span> Limit, Credit) <span class="sc">%&gt;%</span> </span>
<span id="cb195-5"><a href="#cb195-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb195-6"><a href="#cb195-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">model =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb195-7"><a href="#cb195-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb195-8"><a href="#cb195-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb195-9"><a href="#cb195-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb195-10"><a href="#cb195-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb195-11"><a href="#cb195-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Balance <span class="sc">~</span> Rating <span class="sc">+</span> Limit, Credit) <span class="sc">%&gt;%</span> </span>
<span id="cb195-12"><a href="#cb195-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb195-13"><a href="#cb195-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">model =</span><span class="dv">2</span>)</span>
<span id="cb195-14"><a href="#cb195-14" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 6
  term         estimate std.error statistic   p.value model
  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;
1 (Intercept) -173.      43.8        -3.96  9.01e-  5     1
2 Age           -2.29     0.672      -3.41  7.23e-  4     1
3 Limit          0.173    0.00503    34.5   1.63e-121     1
4 (Intercept) -378.      45.3        -8.34  1.21e- 15     2
5 Rating         2.20     0.952       2.31  2.13e-  2     2
6 Limit          0.0245   0.0638      0.384 7.01e-  1     2</code></pre>
</div>
</div>
<p>In the first model both <code>age</code> and <code>limit</code> are statistically significant. In the second, collinearity between <code>limit</code> and <code>raiting</code> has caused standard error for the limit coefficient estimate to increase by a factor of 12 and p-value to increase to 0.701. The importance of the limit variable has been masked due to presence of collinearity.</p>
<p>A simple way to detect collinearity is to look at the correlation matrix of the predictors. Correlation matrix shows the relatinship of two variables but, it is possible for colşinearty to exist between three or more varaibles even if no pair of variables has a particularly high correlation. This situation is called <em>multicollinaerity</em>.</p>
<p>Instead of inspecting the correlatino matrix, better way to assess multicollinaerity is to compute the <em>variance inflation factor</em> (VIF). The VIF is the raio of the variance of <span class="math inline">\(\hat{\beta_j}\)</span> when fitting the model divided by the variance of <span class="math inline">\(\hat{\beta_j}\)</span> if fit on its own.</p>
<p><span class="math display">\[
1 \leq VIF
\]</span> Smallest possible value of VIF is 1: complete absence of collinearity. Usuall there is always some degree of collinearity among the predictors. A VIF that exceeds 5 or 10 indicates a problematic amount of collinaerity.</p>
<p>The VIF for each vairable can be computed using the formula</p>
<p><span class="math display">\[
VIF(\hat{\beta_j}) = \frac{1}{1-R^2_{x_j | x_{-j}}}
\]</span> <span class="math inline">\(R^2_{x_j | x_{-j}}\)</span> is the <span class="math inline">\(R^2\)</span> from a regression of <span class="math inline">\(x_j\)</span> onto all of the other predictors. If <span class="math inline">\(R^2_{x_j | x_{-j}}\)</span> is close to one, then collinearity is present, so VIF will be large.</p>
<div class="cell">
<div class="sourceCode" id="cb197"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb197-3"><a href="#cb197-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb197-4"><a href="#cb197-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(Balance <span class="sc">~</span> Age <span class="sc">+</span> Rating <span class="sc">+</span> Limit, Credit) <span class="sc">%&gt;%</span> </span>
<span id="cb197-5"><a href="#cb197-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb197-6"><a href="#cb197-6" aria-hidden="true" tabindex="-1"></a>  car<span class="sc">::</span><span class="fu">vif</span>() </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       Age     Rating      Limit 
  1.011385 160.668301 160.592880 </code></pre>
</div>
</div>
<p>A regression of balance on age, rating, and limit indicates that the predictors have VIF Values of 1.01, 160.67, 160.59. There is considerable collinearity in the data.</p>
<p>When faced with collinearity, two simple solutions exist: * drop one of the problematic variables from the regression * combine collinear variables together into a single predictor. We might take the average of standardized versions of limit and rating in order to create a new varaible that measures <em>credit worthiness</em>.</p>
<div class="cell">
<div class="sourceCode" id="cb199"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper,advertising) <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio + newspaper, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.8277 -0.8908  0.2418  1.1893  2.8292 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
TV           0.045765   0.001395  32.809   &lt;2e-16 ***
radio        0.188530   0.008611  21.893   &lt;2e-16 ***
newspaper   -0.001037   0.005871  -0.177     0.86    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.686 on 196 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 
F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>To get a anova table;</p>
<div class="cell">
<div class="sourceCode" id="cb201"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(<span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper,advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: sales
           Df Sum Sq Mean Sq   F value Pr(&gt;F)    
TV          1 3314.6  3314.6 1166.7308 &lt;2e-16 ***
radio       1 1545.6  1545.6  544.0501 &lt;2e-16 ***
newspaper   1    0.1     0.1    0.0312 0.8599    
Residuals 196  556.8     2.8                     
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb203"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(<span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper,advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> (Intercept)           TV        radio    newspaper 
 2.938889369  0.045764645  0.188530017 -0.001037493 </code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb205"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper,advertising) <span class="sc">%&gt;%</span> <span class="fu">confint</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                  2.5 %     97.5 %
(Intercept)  2.32376228 3.55401646
TV           0.04301371 0.04851558
radio        0.17154745 0.20551259
newspaper   -0.01261595 0.01054097</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb207"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vcov</span>(<span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper,advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              (Intercept)            TV         radio     newspaper
(Intercept)  0.0972867479 -2.657273e-04 -1.115489e-03 -5.910212e-04
TV          -0.0002657273  1.945737e-06 -4.470395e-07 -3.265950e-07
radio       -0.0011154895 -4.470395e-07  7.415335e-05 -1.780062e-05
newspaper   -0.0005910212 -3.265950e-07 -1.780062e-05  3.446875e-05</code></pre>
</div>
</div>
</section>
</section>
<section id="selecting-best-regression-varaibles" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Selecting best regression varaibles</h1>
<p>You are creating a new regression mdoel or improving an exiting model. You have many regression varaibles and you want to select the vest subset of those varaibles.</p>
<p>The <code>step</code> function can perform stepwise regression, either forward or backward. Backward stepwise regression starts with many varaibles and removes the underperformeners:</p>
<div class="cell">
<div class="sourceCode" id="cb209"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales <span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper, advertising) <span class="co"># full model</span></span>
<span id="cb209-2"><a href="#cb209-2" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(lm, <span class="at">direction =</span> <span class="st">&quot;backward&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">summary</span>() <span class="co"># best model</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=212.79
sales ~ TV + radio + newspaper

            Df Sum of Sq    RSS    AIC
- newspaper  1      0.09  556.9 210.82
&lt;none&gt;                    556.8 212.79
- radio      1   1361.74 1918.6 458.20
- TV         1   3058.01 3614.8 584.90

Step:  AIC=210.82
sales ~ TV + radio

        Df Sum of Sq    RSS    AIC
&lt;none&gt;                556.9 210.82
- radio  1    1545.6 2102.5 474.52
- TV     1    3061.6 3618.5 583.10</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>backward stepwise regression is the easiest approach.</p>
<p>Backward stepwise is easy but sometimes its not feasible to start with everything because you have too many candidate variables. In that case use forward stepwise regression; which will start with nothing and incrementatlly add variables that improve regression. It stops when no further improvement is possible</p>
<div class="cell">
<div class="sourceCode" id="cb212"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales <span class="sc">~</span> <span class="dv">1</span>,advertising)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ 1, data = advertising)

Coefficients:
(Intercept)  
      14.02  </code></pre>
</div>
</div>
<p>we start with minimum model. We must tell step which candidate varaibels are available for inclusing in the model. We use <code>scope</code> argument for that.</p>
<div class="cell">
<div class="sourceCode" id="cb214"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span><span class="dv">1</span>,advertising) <span class="sc">%&gt;%</span> stats<span class="sc">::</span><span class="fu">step</span>(<span class="at">direction =</span> <span class="st">&quot;forward&quot;</span>, <span class="at">scope =</span> (<span class="sc">~</span> TV <span class="sc">+</span> radio <span class="sc">+</span> newspaper), <span class="at">trace =</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span> <span class="fu">summary</span>() </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>we have the same result with backward, in reality these results may differ.</p>
<div class="cell">
<div class="sourceCode" id="cb216"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a>stats<span class="sc">::</span><span class="fu">step</span>(lm, <span class="at">direction =</span> <span class="st">&quot;both&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">summary</span>() </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=212.79
sales ~ TV + radio + newspaper

            Df Sum of Sq    RSS    AIC
- newspaper  1      0.09  556.9 210.82
&lt;none&gt;                    556.8 212.79
- radio      1   1361.74 1918.6 458.20
- TV         1   3058.01 3614.8 584.90

Step:  AIC=210.82
sales ~ TV + radio

            Df Sum of Sq    RSS    AIC
&lt;none&gt;                    556.9 210.82
+ newspaper  1      0.09  556.8 212.79
- radio      1   1545.62 2102.5 474.52
- TV         1   3061.57 3618.5 583.10</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.7977 -0.8752  0.2422  1.1708  2.8328 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.92110    0.29449   9.919   &lt;2e-16 ***
TV           0.04575    0.00139  32.909   &lt;2e-16 ***
radio        0.18799    0.00804  23.382   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.681 on 197 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8962 
F-statistic: 859.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb219"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>MASS<span class="sc">::</span><span class="fu">boxcox</span>(lm)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-119-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>Detecting the outliers :</p>
<div class="cell">
<div class="sourceCode" id="cb220"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">outlierTest</span>(lm)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     rstudent unadjusted p-value Bonferroni p
131 -5.757983          3.267e-08    6.534e-06</code></pre>
</div>
</div>
<p><img src="rcook1.png" class="img-fluid" /></p>
<p><img src="rcook2.png" class="img-fluid" /></p>
<section id="identifying-influential-observations" class="level3" data-number="3.0.1">
<h3 data-number="3.0.1"><span class="header-section-number">3.0.1</span> Identifying Influential observations</h3>
<p>You want to identify the observatipons that are having the ost influence on the regression model, this is useful for diagnosing possible porblems with the data.</p>
<p><strong>Solution</strong></p>
<p>The <code>influence.measures</code> function reports several useful statistics for identifying inflıuentioal obs. and it flags the significant ones with an asterisk(*).</p>
<div class="cell">
<div class="sourceCode" id="cb222"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> newspaper,advertising)</span>
<span id="cb222-2"><a href="#cb222-2" aria-hidden="true" tabindex="-1"></a>lm <span class="sc">%&gt;%</span> <span class="fu">summary</span>() <span class="sc">%&gt;%</span> <span class="fu">print</span>() <span class="co"># r2 is 0.6422</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + newspaper, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.6231 -1.7346 -0.0948  1.8926  8.4512 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 5.774948   0.525338  10.993  &lt; 2e-16 ***
TV          0.046901   0.002581  18.173  &lt; 2e-16 ***
newspaper   0.044219   0.010174   4.346 2.22e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 3.121 on 197 degrees of freedom
Multiple R-squared:  0.6458,    Adjusted R-squared:  0.6422 
F-statistic: 179.6 on 2 and 197 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode" id="cb224"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>inf <span class="ot">=</span> <span class="fu">influence.measures</span>(lm)</span></code></pre></div>
</div>
<p>We need to filter for columns which has at least one true:</p>
<div class="cell">
<div class="sourceCode" id="cb225"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(inf<span class="sc">$</span>is.inf) <span class="sc">%&gt;%</span> <span class="fu">as_tibble</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb225-2"><a href="#cb225-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">obs =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb225-3"><a href="#cb225-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">if_any</span>(<span class="fu">everything</span>(), <span class="sc">~</span>. <span class="sc">==</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span> <span class="fu">print</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb225-4"><a href="#cb225-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pull</span>(<span class="st">&quot;obs&quot;</span>) <span class="ot">-&gt;</span> infss</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 13 × 8
   dfb.1_ dfb.TV dfb.nwsp dffit cov.r cook.d hat     obs
   &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt;    &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;  &lt;lgl&gt; &lt;int&gt;
 1 FALSE  FALSE  FALSE    FALSE FALSE FALSE  FALSE     1
 2 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE     3
 3 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE     6
 4 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE    13
 5 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  TRUE     17
 6 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE    26
 7 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  TRUE     76
 8 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  TRUE    102
 9 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE   119
10 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE   129
11 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE   132
12 FALSE  FALSE  FALSE    TRUE  TRUE  FALSE  FALSE   166
13 FALSE  FALSE  FALSE    FALSE TRUE  FALSE  FALSE   179</code></pre>
</div>
<div class="sourceCode" id="cb227"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>infss</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1]   1   3   6  13  17  26  76 102 119 129 132 166 179</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode" id="cb229"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> newspaper,advertising[<span class="sc">-</span>infss,]) <span class="sc">%&gt;%</span> <span class="fu">summary</span>() <span class="co"># r^2 improves!</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + newspaper, data = advertising[-infss, 
    ])

Residuals:
    Min      1Q  Median      3Q     Max 
-7.2432 -1.6062 -0.0775  1.9088  6.9490 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 5.348561   0.512438   10.44  &lt; 2e-16 ***
TV          0.047992   0.002574   18.65  &lt; 2e-16 ***
newspaper   0.058656   0.011501    5.10  8.4e-07 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 2.918 on 184 degrees of freedom
Multiple R-squared:  0.6866,    Adjusted R-squared:  0.6832 
F-statistic: 201.6 on 2 and 184 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode" id="cb231"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a>lm12 <span class="ot">&lt;-</span><span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> newspaper,advertising[<span class="sc">-</span>infss,])</span></code></pre></div>
</div>
</section>
<section id="testing-residuals-for-autocorrelation" class="level2" data-number="3.1">
<h2 data-number="3.1"><span class="header-section-number">3.1</span> testing residuals for autocorrelation</h2>
<div class="cell">
<div class="sourceCode" id="cb232"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Zorunlu paket yükleniyor: zoo</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: &#39;zoo&#39;</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from &#39;package:base&#39;:

    as.Date, as.Date.numeric</code></pre>
</div>
<div class="sourceCode" id="cb236"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb236-1"><a href="#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dwtest</span>(lm) </span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Durbin-Watson test

data:  lm
DW = 1.9685, p-value = 0.4097
alternative hypothesis: true autocorrelation is greater than 0</code></pre>
</div>
</div>
<p>if $ p &gt; 0.05$ no evidence of correaltion.</p>
</section>
<section id="the-marketing-plan" class="level2" data-number="3.2">
<h2 data-number="3.2"><span class="header-section-number">3.2</span> The Marketing Plan</h2>
<p>Lets go back to our 7 questions about the <code>advertising</code>data:</p>
<ol type="1">
<li><em>Is there a relationship between advertising sales and budget?</em></li>
</ol>
<pre><code>To get an answer to this question, we regress `sales` onto our budget related varaibles `TV`, `radio`, and `newspaper` and test the hypothesis $H_0: \beta_{TV}=\beta_{radio}=\beta_{newspaper} = 0$ with F-statistic.</code></pre>
<div class="cell">
<div class="sourceCode" id="cb239"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>advertising <span class="sc">%&lt;&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="st">&quot;sales_hat&quot;</span>)</span>
<span id="cb239-2"><a href="#cb239-2" aria-hidden="true" tabindex="-1"></a><span class="fu">linear_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb239-3"><a href="#cb239-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb239-4"><a href="#cb239-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb239-5"><a href="#cb239-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(sales <span class="sc">~</span>., advertising) <span class="sc">%&gt;%</span> </span>
<span id="cb239-6"><a href="#cb239-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pluck</span>(<span class="st">&quot;fit&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb239-7"><a href="#cb239-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
stats::lm(formula = sales ~ ., data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.8277 -0.8908  0.2418  1.1893  2.8292 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.938889   0.311908   9.422   &lt;2e-16 ***
TV           0.045765   0.001395  32.809   &lt;2e-16 ***
radio        0.188530   0.008611  21.893   &lt;2e-16 ***
newspaper   -0.001037   0.005871  -0.177     0.86    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.686 on 196 degrees of freedom
Multiple R-squared:  0.8972,    Adjusted R-squared:  0.8956 
F-statistic: 570.3 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>In this case the p-value corresponding to the F-statistic is very low, indicating a clear evidence of a relationship between advertising and sales.</p>
<ol start="2" type="1">
<li><p><em>How strong is the relationship?</em></p>
<p>This is about model accuracy. We can check <span class="math inline">\(R^2\)</span>; the predictors explain almost 90% of the variance in <code>sales</code>.</p></li>
<li><p><em>Which media contribute to sales?</em></p>
<p>We check p values of the coefficients. newspaper is not statistically significant; only <code>TV</code> and <code>radio</code> are realated to sales.</p></li>
<li><p><em>How large is the effect of each medium on sales?</em></p></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb241"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span>.,advertising) <span class="sc">%&gt;%</span></span>
<span id="cb241-2"><a href="#cb241-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">dwplot</span>(<span class="at">ci =</span> <span class="fl">0.95</span>,<span class="at">dot_args =</span> <span class="fu">list</span>(<span class="at">size=</span><span class="dv">2</span>), <span class="at">vline =</span> <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;grey50&quot;</span>, <span class="at">linetype =</span><span class="dv">2</span>))</span></code></pre></div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-126-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<pre><code>We use standard errors to construct confidence intervals for the coefficients. If any of the confidence intervals include 0 that predictor is not statistically significant. Collinearty can result in very wide standard errors; making confint to include zero. Was the collineary the reason that confint of newspaper to be so wide? Lets check VIF scores</code></pre>
<div class="cell">
<div class="sourceCode" id="cb243"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(<span class="fu">lm</span>(sales<span class="sc">~</span>.,advertising))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       TV     radio newspaper 
 1.004611  1.144952  1.145187 </code></pre>
</div>
</div>
<p>No all the VIF scores suggest no evidence of collinearity.</p>
<ol start="5" type="1">
<li><p><em>How accurately can we predict future sales?</em></p>
<p>After deciding on our model</p></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb245"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span>TV<span class="sc">+</span>radio <span class="sc">+</span> TV <span class="sc">*</span> radio, advertising) <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio + TV * radio, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.3366 -0.4028  0.1831  0.5948  1.5246 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***
TV          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***
radio       2.886e-02  8.905e-03   3.241   0.0014 ** 
TV:radio    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9435 on 196 degrees of freedom
Multiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 
F-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<pre><code>The accuracy of our estimation depends on whether we wish to predict an individual response, $Y = f(X) + \epsilon$, or the average response, $f(X)$. If the former we use a prediction interval, and if the latter, we use a confidecen interval. Prediction intervals will always be wider than confidence intervals because they account for the uncertainty assocaited with $\epsilon$, the irreducible error.</code></pre>
<ol start="6" type="1">
<li><p><em>Is the relationship linear?</em></p>
<p>We can use residual plots to identify non-linearity: the plot will show a pattern.</p></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb248"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio, advertising) <span class="sc">%&gt;%</span> <span class="fu">augment</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb248-2"><a href="#cb248-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> <span class="fu">aes</span>(<span class="at">x =</span> .hat, <span class="at">y =</span> .fitted) <span class="sc">+</span> <span class="fu">geom_point</span>() <span class="sc">+</span> <span class="fu">geom_smooth</span>(<span class="at">se =</span> F)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39;</code></pre>
</div>
<div class="cell-output-display">
<p><img src="Chapter3_files/figure-html/unnamed-chunk-129-1.png" class="img-fluid" width="672" /></p>
</div>
</div>
<p>the model seems okay. If we had encountered a non-linearity we would have to make transformations to the predictors.</p>
<ol start="7" type="1">
<li><p><em>Is there synergy among the advertising media?</em></p>
<p>LR assumes additive relationship. When we account for interacation term our model is improved and the interaction term was statistically significant.</p></li>
</ol>
<div class="cell">
<div class="sourceCode" id="cb250"><pre class="sourceCode r cell-code"><code class="sourceCode r"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(sales<span class="sc">~</span>TV <span class="sc">+</span> radio <span class="sc">+</span> radio <span class="sc">*</span> TV, advertising) <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = sales ~ TV + radio + radio * TV, data = advertising)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.3366 -0.4028  0.1831  0.5948  1.5246 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 6.750e+00  2.479e-01  27.233   &lt;2e-16 ***
TV          1.910e-02  1.504e-03  12.699   &lt;2e-16 ***
radio       2.886e-02  8.905e-03   3.241   0.0014 ** 
TV:radio    1.086e-03  5.242e-05  20.727   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.9435 on 196 degrees of freedom
Multiple R-squared:  0.9678,    Adjusted R-squared:  0.9673 
F-statistic:  1963 on 3 and 196 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</section>
<section id="comparison-of-linear-regression-with-k-nearest-neighbors" class="level2" data-number="3.3">
<h2 data-number="3.3"><span class="header-section-number">3.3</span> Comparison of Linear Regression with K-Nearest Neighbors</h2>
<p>Linear regression is a parametric approach because it assumes a linear functinoal form for <span class="math inline">\(f(x)\)</span>. Parametric approaches are easy to fit, coefficients have simple interpretations and test of statistical significance can be easily performed. But they make strong assumptions about the form of <span class="math inline">\(f(X)\)</span>. If the assumed functional for is not correct, and the prediciton is our goal, then we see a poor performance of fit.</p>
<p>In contrast, <em>non-parametric</em> methods do not explicity assume a parametric for of <span class="math inline">\(f(X)\)</span>, so they provide a more flexible approach for performing regression. One of a non-parametric method is <em>K-nearest neighbors regressin</em> (KNN regression) .</p>
<p>The KNN regression method is closely related to the KNN classifier in Chapter 2. Given a value for <em>K</em> and a prediciton point <span class="math inline">\(x_0\)</span>, KNN regression first identifies the <em>K</em> traiinng observations that are closest to <span class="math inline">\(x_0\)</span> represented by <span class="math inline">\(N_0\)</span>. It then estimates <span class="math inline">\(f(x_0)\)</span> using the average of all the training responses in <span class="math inline">\(N_0\)</span>. In other words:</p>
<p><span class="math display">\[
\hat{f}(x_0) = \frac{1}{K}\sum_{x \in N_0} y_i
\]</span></p>
<p>The optimal <span class="math inline">\(K\)</span> value will depend on the <em>bias-variance tradeoff</em>. A small value for <span class="math inline">\(K\)</span> provides the most flexile fit, which will have low bias but high variance. This variance is due to the fact that the prediciton in a given region is entirely dependent on just one obsrvation. In contrast, larger values of <span class="math inline">\(K\)</span> will provide a smoother and less variable fit; the prediction in a region is an average of several points, and so changing one observation has a smaller effect. However, the smoothing may cause bias by masking some of the structure in <span class="math inline">\(f(x)\)</span>. Chapter 5 will introduce several approaches for estiamting test error rates which can be used to identify the optimal <span class="math inline">\(K\)</span> in KNN regression.</p>
<p><em>The parametric approach will outperform the non-parametric approach if the parametric form that has been selected is close to the true for of</em> <span class="math inline">\(f\)</span>.</p>
<p><img src="fig3.17.png" class="img-fluid" /></p>
<p>in Figure one true relationship is linear, represented by the black line. Blue curves response to the KNN fits using <span class="math inline">\(K=1\)</span> and <span class="math inline">\(K=9\)</span>. <span class="math inline">\(K=9\)</span> is much closer to <span class="math inline">\(f(x)\)</span>. However, since the true relationship is linear, KNN approach cannot compete with a linear regression; a non-parametric approach incurs a cost in variance that is not offset by reduction in bias.</p>
<p><img src="fig3.18.png" class="img-fluid" /></p>
<p>The blue dashed line is the OLS regression which outperfroms KNN for this data. Green sloid line, plotted as a function of <span class="math inline">\(1/K\)</span> represents the test set mean squared error(MSE) for KNN. The KNN errors are wlell above the black dashed line, which is the test MSE for linear regression. When K is large KNN performs only a little worse that least squares regression in terms of MSE. It performs far worse when K is small.</p>
<p>In practice true relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is rarely exactly linear.</p>
<p><img src="fig3.19.png" class="img-fluid" /></p>
<p>Fig 3.10 examines the relative performances of OLS regression and KNN under increasing levels of non-linearity in the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. In the top row, the true relationship is nearly linear. In this case we see that test MSE for linear regression is still superior to that of KNN for low values of K. However, fro <span class="math inline">\(4 \leq K\)</span> KNN outperforms linear regression. The secodn row has more non-linearity. In this case KNN is better for all valeus of K.</p>
<p>So, KNN performs slightly worse than linear regression when the relationship is linear, but much better for non-linear situations. Does this mean we should favour KNN In relaity because the relationships are rarely linear? No, in relaity, even when the true relationship is highly non linear, KNN may still provide inferior resutls to linear regression. Fig 3-18 and 19 had <span class="math inline">\(p=1\)</span>, but for larger <span class="math inline">\(p\)</span> KNN often performs worse than linear regression.</p>
<p><img src="fig3.20.png" class="img-fluid" /></p>
<p>Fig 20 shows a strong non-linear situation. When <span class="math inline">\(p=1\)</span>or <span class="math inline">\(p=2\)</span> KNN is better, but for <span class="math inline">\(p=3\)</span> results are mixed, for <span class="math inline">\(4\leqp\)</span> LR is superior. <em>This decrease in performance as the dimensions increases is a common problem for KNN</em></p>
<p>As a general rule parametric methods will tend to outperform non-parametric approaches when there is small number of observations per predictor.</p>
<div id="quarto-navigation-envelope" class="hidden">
<p><span class="hidden" data-render-id="quarto-int-sidebar-title">ISLR-R21._1</span> <span class="hidden" data-render-id="quarto-int-navbar-title">ISLR-R21._1</span> <span class="hidden" data-render-id="quarto-int-next"><span class="chapter-number">3</span>  <span class="chapter-title">Exercise</span></span> <span class="hidden" data-render-id="quarto-int-prev"><span class="chapter-number">1</span>  <span class="chapter-title">What Is Statistical Learning?</span></span> <span class="hidden" data-render-id="quarto-int-sidebar:/index.html">Preface</span> <span class="hidden" data-render-id="quarto-int-sidebar:/Chapter2.html"><span class="chapter-number">1</span>  <span class="chapter-title">What Is Statistical Learning?</span></span> <span class="hidden" data-render-id="quarto-int-sidebar:/Chapter3.html"><span class="chapter-number">2</span>  <span class="chapter-title">Linear Regression</span></span> <span class="hidden" data-render-id="quarto-int-sidebar:/analysis.html"><span class="chapter-number">3</span>  <span class="chapter-title">Exercise</span></span> <span class="hidden" data-render-id="quarto-int-sidebar:/Chapter4.html"><span class="chapter-number">4</span>  <span class="chapter-title">Classification</span></span> <span class="hidden" data-render-id="quarto-breadcrumbs-8a2e1512a9d07a9959b253976044bb1b"><span class="chapter-number">2</span>  <span class="chapter-title">Linear Regression</span></span></p>
</div>
<div id="quarto-meta-markdown" class="hidden">
<p><span class="hidden" data-render-id="quarto-metatitle">ISLR-R21._1 - <span class="chapter-number">2</span>  <span class="chapter-title">Linear Regression</span></span> <span class="hidden" data-render-id="quarto-twittercardtitle">ISLR-R21._1 - <span class="chapter-number">2</span>  <span class="chapter-title">Linear Regression</span></span> <span class="hidden" data-render-id="quarto-ogcardtitle">ISLR-R21._1 - <span class="chapter-number">2</span>  <span class="chapter-title">Linear Regression</span></span> <span class="hidden" data-render-id="quarto-metasitename">ISLR-R21._1</span> <span class="hidden" data-render-id="quarto-twittercarddesc"></span> <span class="hidden" data-render-id="quarto-ogcardddesc"></span></p>
</div>
</section>
</section>

</main> <!-- /main -->
<script id = "quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a  href="/Chapter2.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class='chapter-number'>1</span>  <span class='chapter-title'>What Is Statistical Learning?</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a  href="/analysis.html" class="pagination-link">
        <span class="nav-page-text"><span class='chapter-number'>3</span>  <span class='chapter-title'>Exercise</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->

</body>

</html>